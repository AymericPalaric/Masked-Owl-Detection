{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.transform import GeneralizedRCNNTransform\n",
    "from torchvision.models.detection.backbone_utils import mobilenet_backbone\n",
    "\n",
    "from torchvision.models.detection.anchor_utils import AnchorGenerator\n",
    "nn = torch.nn\n",
    "import os\n",
    "import numpy as np\n",
    "from src.utils.audio_utils import compute_spectrogram, load_audio_file\n",
    "from src.utils import path_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneShotDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, detection_dir,transform_audio, device):\n",
    "        self.detection_dir = detection_dir\n",
    "        self.device = device\n",
    "        self.samplepath = os.path.join(self.detection_dir, 'samples')\n",
    "        self.targetpath = os.path.join(self.detection_dir, 'target')\n",
    "        self.indexes = list(map(lambda x: x.split('.')[0],os.listdir(self.samplepath)))\n",
    "        self.transform_audio = transform_audio\n",
    "        self.transform_image = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "        self.spec_hight=120\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir((self.samplepath)))\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        index=self.indexes[idx]\n",
    "        data,fs = load_audio_file(os.path.join(self.samplepath,index +'.wav'))\n",
    "        targets = np.load(os.path.join(self.targetpath,index +'.npy'))\n",
    "        data = self.transform_audio(data)\n",
    "        boxes=torch.as_tensor([[start,0,end,data.shape[0]] for [_,start,end]in targets], dtype=torch.float32)\n",
    "        labels=torch.as_tensor([target[0] for target in targets], dtype=torch.int32)\n",
    "        #target_dict={'boxes':boxes,'labels':labels}\n",
    "        # targets=[{'boxes':torch.as_tensor([start,0,end,data.shape[0]], dtype=torch.float32),'labels':lbl} for [lbl,start,end]in targets]\n",
    "        x = self.transform_image(data)\n",
    "        return x, boxes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([[[ -48.4338,  -48.0510,  -46.7459,  ...,  -44.4542,  -46.1067,\n",
      "           -47.8241],\n",
      "         [ -56.6873,  -44.9814,  -46.9355,  ...,  -39.1955,  -46.6519,\n",
      "           -50.3317],\n",
      "         [ -46.3867,  -54.8088,  -59.3137,  ...,  -43.2027,  -63.1286,\n",
      "           -50.2026],\n",
      "         ...,\n",
      "         [ -97.3052,  -91.5861,  -84.6041,  ...,  -89.6452,  -93.3256,\n",
      "           -85.4067],\n",
      "         [ -94.4468,  -90.0997,  -84.4939,  ...,  -87.5063,  -98.0471,\n",
      "           -88.4591],\n",
      "         [ -89.2727,  -97.7166, -103.3719,  ...,  -95.3397,  -95.2801,\n",
      "           -93.7884]]]), {'boxes': tensor([[2.7266e+04, 0.0000e+00, 4.3424e+04, 1.2000e+02],\n",
      "        [4.6030e+03, 0.0000e+00, 3.4288e+04, 1.2000e+02],\n",
      "        [3.8040e+03, 0.0000e+00, 3.2598e+04, 1.2000e+02],\n",
      "        [1.7443e+04, 0.0000e+00, 4.0532e+04, 1.2000e+02],\n",
      "        [1.4340e+03, 0.0000e+00, 4.7866e+04, 1.2000e+02],\n",
      "        [3.7460e+03, 0.0000e+00, 4.2519e+04, 1.2000e+02],\n",
      "        [3.3000e+01, 0.0000e+00, 4.5554e+04, 1.2000e+02],\n",
      "        [1.3210e+03, 0.0000e+00, 4.5577e+04, 1.2000e+02],\n",
      "        [5.5680e+03, 0.0000e+00, 4.7548e+04, 1.2000e+02],\n",
      "        [9.5400e+02, 0.0000e+00, 4.6437e+04, 1.2000e+02],\n",
      "        [4.0010e+03, 0.0000e+00, 4.7878e+04, 1.2000e+02],\n",
      "        [3.0550e+03, 0.0000e+00, 4.6864e+04, 1.2000e+02],\n",
      "        [5.0000e+00, 0.0000e+00, 4.7919e+04, 1.2000e+02],\n",
      "        [2.9250e+03, 0.0000e+00, 4.6390e+04, 1.2000e+02],\n",
      "        [3.6800e+02, 0.0000e+00, 4.7444e+04, 1.2000e+02],\n",
      "        [6.2850e+03, 0.0000e+00, 4.6449e+04, 1.2000e+02],\n",
      "        [5.1960e+03, 0.0000e+00, 4.7987e+04, 1.2000e+02],\n",
      "        [6.1000e+01, 0.0000e+00, 4.7792e+04, 1.2000e+02],\n",
      "        [6.8080e+03, 0.0000e+00, 4.5282e+04, 1.2000e+02],\n",
      "        [4.5900e+03, 0.0000e+00, 4.5284e+04, 1.2000e+02],\n",
      "        [1.5710e+03, 0.0000e+00, 4.4306e+04, 1.2000e+02],\n",
      "        [3.3400e+02, 0.0000e+00, 4.4056e+04, 1.2000e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]), 'labels': tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)}), (tensor([[[-66.6349, -75.6991, -65.1070,  ..., -74.0318, -62.8794, -62.8950],\n",
      "         [-65.6750, -67.4152, -57.1148,  ..., -59.4120, -60.3458, -61.1655],\n",
      "         [-65.8426, -65.4191, -60.5271,  ..., -54.5421, -59.5365, -59.4433],\n",
      "         ...,\n",
      "         [-87.1333, -87.8860, -88.1010,  ..., -87.3415, -85.7258, -89.4154],\n",
      "         [-92.7180, -89.3849, -86.5069,  ..., -80.8646, -86.5759, -87.7484],\n",
      "         [-82.0067, -85.9837, -89.6169,  ..., -85.3839, -95.5414, -94.7156]]]), {'boxes': tensor([[ 3122.,     0., 39582.,   120.],\n",
      "        [12472.,     0., 31461.,   120.],\n",
      "        [21228.,     0., 38628.,   120.],\n",
      "        [11969.,     0., 41813.,   120.],\n",
      "        [ 9754.,     0., 35406.,   120.],\n",
      "        [  388.,     0., 47078.,   120.],\n",
      "        [ 5436.,     0., 47433.,   120.],\n",
      "        [   72.,     0., 44590.,   120.],\n",
      "        [  413.,     0., 47960.,   120.],\n",
      "        [  338.,     0., 47860.,   120.],\n",
      "        [ 6301.,     0., 47574.,   120.],\n",
      "        [  303.,     0., 45875.,   120.],\n",
      "        [  425.,     0., 42453.,   120.],\n",
      "        [ 3563.,     0., 47065.,   120.],\n",
      "        [  691.,     0., 47985.,   120.],\n",
      "        [  853.,     0., 45020.,   120.],\n",
      "        [ 3755.,     0., 42439.,   120.],\n",
      "        [ 2813.,     0., 45852.,   120.],\n",
      "        [ 2708.,     0., 44766.,   120.],\n",
      "        [ 2631.,     0., 43469.,   120.],\n",
      "        [  896.,     0., 45186.,   120.],\n",
      "        [  344.,     0., 46809.,   120.],\n",
      "        [ 2374.,     0., 41325.,   120.],\n",
      "        [ 3738.,     0., 46740.,   120.],\n",
      "        [ 4126.,     0., 42907.,   120.],\n",
      "        [  229.,     0., 45841.,   120.],\n",
      "        [  130.,     0., 43761.,   120.],\n",
      "        [ 1149.,     0., 47752.,   120.],\n",
      "        [ 2333.,     0., 47606.,   120.],\n",
      "        [ 2053.,     0., 47162.,   120.],\n",
      "        [    0.,     0.,     0.,     0.],\n",
      "        [    0.,     0.,     0.,     0.]]), 'labels': tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)}), (tensor([[[-53.8202, -56.9945, -48.1087,  ..., -55.1666, -50.7853, -51.5929],\n",
      "         [-51.8512, -78.5396, -51.4568,  ..., -55.4072, -56.3119, -53.1597],\n",
      "         [-57.2402, -58.1699, -50.7922,  ..., -47.5358, -59.4872, -60.0800],\n",
      "         ...,\n",
      "         [-78.7768, -87.9929, -82.2773,  ..., -83.6740, -81.3124, -78.6865],\n",
      "         [-77.8977, -81.8717, -78.8960,  ..., -83.9767, -78.7257, -80.8819],\n",
      "         [-79.1585, -76.2664, -97.3125,  ..., -80.8158, -73.3697, -93.6864]]]), {'boxes': tensor([[8.2200e+02, 0.0000e+00, 3.2033e+04, 1.2000e+02],\n",
      "        [1.7553e+04, 0.0000e+00, 4.1192e+04, 1.2000e+02],\n",
      "        [2.0894e+04, 0.0000e+00, 3.9991e+04, 1.2000e+02],\n",
      "        [2.1293e+04, 0.0000e+00, 4.2942e+04, 1.2000e+02],\n",
      "        [4.5960e+03, 0.0000e+00, 3.0110e+04, 1.2000e+02],\n",
      "        [8.0600e+03, 0.0000e+00, 3.4705e+04, 1.2000e+02],\n",
      "        [8.1800e+02, 0.0000e+00, 4.6235e+04, 1.2000e+02],\n",
      "        [8.3700e+02, 0.0000e+00, 4.2566e+04, 1.2000e+02],\n",
      "        [1.5690e+03, 0.0000e+00, 4.6973e+04, 1.2000e+02],\n",
      "        [6.4600e+02, 0.0000e+00, 4.5414e+04, 1.2000e+02],\n",
      "        [1.5000e+01, 0.0000e+00, 4.4799e+04, 1.2000e+02],\n",
      "        [3.8730e+03, 0.0000e+00, 4.4035e+04, 1.2000e+02],\n",
      "        [5.5100e+03, 0.0000e+00, 4.5901e+04, 1.2000e+02],\n",
      "        [5.8840e+03, 0.0000e+00, 4.5492e+04, 1.2000e+02],\n",
      "        [5.6070e+03, 0.0000e+00, 4.4987e+04, 1.2000e+02],\n",
      "        [4.9380e+03, 0.0000e+00, 4.4060e+04, 1.2000e+02],\n",
      "        [2.0630e+03, 0.0000e+00, 4.6952e+04, 1.2000e+02],\n",
      "        [5.4130e+03, 0.0000e+00, 4.6489e+04, 1.2000e+02],\n",
      "        [2.6490e+03, 0.0000e+00, 4.1795e+04, 1.2000e+02],\n",
      "        [4.7410e+03, 0.0000e+00, 4.4336e+04, 1.2000e+02],\n",
      "        [5.4550e+03, 0.0000e+00, 4.6678e+04, 1.2000e+02],\n",
      "        [3.4500e+03, 0.0000e+00, 4.6392e+04, 1.2000e+02],\n",
      "        [1.7700e+02, 0.0000e+00, 4.6935e+04, 1.2000e+02],\n",
      "        [2.1330e+03, 0.0000e+00, 4.6926e+04, 1.2000e+02],\n",
      "        [7.3500e+02, 0.0000e+00, 4.5368e+04, 1.2000e+02],\n",
      "        [2.9500e+02, 0.0000e+00, 4.1055e+04, 1.2000e+02],\n",
      "        [1.4350e+03, 0.0000e+00, 4.7822e+04, 1.2000e+02],\n",
      "        [6.3200e+02, 0.0000e+00, 4.7868e+04, 1.2000e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)}), (tensor([[[-61.4342, -55.8958, -68.8828,  ..., -49.2965, -54.9066, -62.0683],\n",
      "         [-52.9668, -56.7035, -64.6483,  ..., -55.8716, -54.2807, -57.2114],\n",
      "         [-49.0250, -63.3394, -77.6278,  ..., -64.0544, -54.0333, -66.3048],\n",
      "         ...,\n",
      "         [-84.9774, -89.3918, -88.4404,  ..., -85.6085, -87.3094, -90.4365],\n",
      "         [-91.2570, -85.5788, -90.2185,  ..., -86.5498, -88.8906, -97.4105],\n",
      "         [-89.0226, -84.3201, -97.2360,  ..., -98.2021, -94.3365, -90.7104]]]), {'boxes': tensor([[8.8730e+03, 0.0000e+00, 3.7080e+04, 1.2000e+02],\n",
      "        [1.1231e+04, 0.0000e+00, 3.2952e+04, 1.2000e+02],\n",
      "        [1.1965e+04, 0.0000e+00, 4.1666e+04, 1.2000e+02],\n",
      "        [8.8390e+03, 0.0000e+00, 2.9177e+04, 1.2000e+02],\n",
      "        [8.2100e+03, 0.0000e+00, 3.6588e+04, 1.2000e+02],\n",
      "        [7.5800e+02, 0.0000e+00, 4.0788e+04, 1.2000e+02],\n",
      "        [1.3920e+03, 0.0000e+00, 4.6664e+04, 1.2000e+02],\n",
      "        [7.5640e+03, 0.0000e+00, 4.6479e+04, 1.2000e+02],\n",
      "        [5.0600e+02, 0.0000e+00, 4.7062e+04, 1.2000e+02],\n",
      "        [1.1000e+01, 0.0000e+00, 4.7823e+04, 1.2000e+02],\n",
      "        [4.2470e+03, 0.0000e+00, 4.7721e+04, 1.2000e+02],\n",
      "        [5.7200e+02, 0.0000e+00, 4.7959e+04, 1.2000e+02],\n",
      "        [1.3910e+03, 0.0000e+00, 4.7759e+04, 1.2000e+02],\n",
      "        [1.5610e+03, 0.0000e+00, 4.5204e+04, 1.2000e+02],\n",
      "        [4.2590e+03, 0.0000e+00, 4.4693e+04, 1.2000e+02],\n",
      "        [4.8470e+03, 0.0000e+00, 4.5965e+04, 1.2000e+02],\n",
      "        [8.8000e+01, 0.0000e+00, 4.7203e+04, 1.2000e+02],\n",
      "        [5.5780e+03, 0.0000e+00, 4.7140e+04, 1.2000e+02],\n",
      "        [1.3390e+03, 0.0000e+00, 4.0212e+04, 1.2000e+02],\n",
      "        [2.9530e+03, 0.0000e+00, 4.3315e+04, 1.2000e+02],\n",
      "        [1.7100e+02, 0.0000e+00, 4.0614e+04, 1.2000e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]), 'labels': tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)}), (tensor([[[ -51.9974,  -42.8204,  -47.2124,  ...,  -44.3189,  -44.8318,\n",
      "           -49.0566],\n",
      "         [ -47.4627,  -40.1927,  -46.8837,  ...,  -41.1421,  -45.6582,\n",
      "           -48.5714],\n",
      "         [ -44.4127,  -43.3078,  -57.0158,  ...,  -42.0414,  -57.7087,\n",
      "           -46.9225],\n",
      "         ...,\n",
      "         [ -92.1214,  -96.2768,  -87.3809,  ..., -112.2729,  -86.1726,\n",
      "           -92.6410],\n",
      "         [ -98.3063,  -91.8687,  -89.4987,  ...,  -90.2552,  -81.3453,\n",
      "           -92.1551],\n",
      "         [ -93.4860,  -90.1737,  -95.9672,  ...,  -91.7347,  -83.6661,\n",
      "           -85.4530]]]), {'boxes': tensor([[9.7110e+03, 0.0000e+00, 4.5993e+04, 1.2000e+02],\n",
      "        [1.9290e+03, 0.0000e+00, 2.8440e+04, 1.2000e+02],\n",
      "        [1.1130e+04, 0.0000e+00, 4.7901e+04, 1.2000e+02],\n",
      "        [1.9560e+03, 0.0000e+00, 4.7402e+04, 1.2000e+02],\n",
      "        [3.1980e+03, 0.0000e+00, 4.3958e+04, 1.2000e+02],\n",
      "        [1.1000e+01, 0.0000e+00, 4.1550e+04, 1.2000e+02],\n",
      "        [4.7110e+03, 0.0000e+00, 4.6648e+04, 1.2000e+02],\n",
      "        [2.7500e+02, 0.0000e+00, 4.0051e+04, 1.2000e+02],\n",
      "        [4.4050e+03, 0.0000e+00, 4.7030e+04, 1.2000e+02],\n",
      "        [8.8900e+02, 0.0000e+00, 4.7499e+04, 1.2000e+02],\n",
      "        [1.0780e+03, 0.0000e+00, 4.5024e+04, 1.2000e+02],\n",
      "        [6.1700e+02, 0.0000e+00, 4.7713e+04, 1.2000e+02],\n",
      "        [4.6680e+03, 0.0000e+00, 4.4091e+04, 1.2000e+02],\n",
      "        [2.1740e+03, 0.0000e+00, 4.6095e+04, 1.2000e+02],\n",
      "        [1.1560e+04, 0.0000e+00, 4.5343e+04, 1.2000e+02],\n",
      "        [7.0000e+01, 0.0000e+00, 4.7891e+04, 1.2000e+02],\n",
      "        [4.2300e+03, 0.0000e+00, 4.7886e+04, 1.2000e+02],\n",
      "        [3.9000e+01, 0.0000e+00, 4.7865e+04, 1.2000e+02],\n",
      "        [3.4300e+02, 0.0000e+00, 4.5029e+04, 1.2000e+02],\n",
      "        [1.1770e+03, 0.0000e+00, 4.2991e+04, 1.2000e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]), 'labels': tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)}), (tensor([[[-52.6855, -68.1454, -50.6965,  ..., -57.5721, -55.3951, -56.6634],\n",
      "         [-51.2313, -61.3279, -50.1575,  ..., -60.4636, -58.0126, -49.4321],\n",
      "         [-54.5274, -69.1210, -54.6480,  ..., -54.4739, -57.6918, -46.4135],\n",
      "         ...,\n",
      "         [-80.5008, -81.0101, -84.2792,  ..., -89.7046, -84.8476, -89.0659],\n",
      "         [-83.7097, -81.5814, -75.2230,  ..., -81.0233, -80.8302, -90.8567],\n",
      "         [-81.1261, -92.5907, -77.9809,  ..., -82.4923, -76.6376, -84.0812]]]), {'boxes': tensor([[4.0850e+03, 0.0000e+00, 3.6934e+04, 1.2000e+02],\n",
      "        [5.6500e+02, 0.0000e+00, 3.1524e+04, 1.2000e+02],\n",
      "        [5.4360e+03, 0.0000e+00, 4.7707e+04, 1.2000e+02],\n",
      "        [6.8270e+03, 0.0000e+00, 4.0315e+04, 1.2000e+02],\n",
      "        [1.5388e+04, 0.0000e+00, 4.4453e+04, 1.2000e+02],\n",
      "        [9.4270e+03, 0.0000e+00, 2.9701e+04, 1.2000e+02],\n",
      "        [3.9780e+03, 0.0000e+00, 4.5584e+04, 1.2000e+02],\n",
      "        [1.1300e+02, 0.0000e+00, 4.4609e+04, 1.2000e+02],\n",
      "        [1.8840e+03, 0.0000e+00, 4.3440e+04, 1.2000e+02],\n",
      "        [5.7680e+03, 0.0000e+00, 4.4234e+04, 1.2000e+02],\n",
      "        [1.7700e+02, 0.0000e+00, 4.7998e+04, 1.2000e+02],\n",
      "        [5.9000e+02, 0.0000e+00, 4.4017e+04, 1.2000e+02],\n",
      "        [9.2100e+02, 0.0000e+00, 4.5727e+04, 1.2000e+02],\n",
      "        [7.3260e+03, 0.0000e+00, 4.7329e+04, 1.2000e+02],\n",
      "        [9.1900e+02, 0.0000e+00, 4.1148e+04, 1.2000e+02],\n",
      "        [4.8130e+03, 0.0000e+00, 4.5379e+04, 1.2000e+02],\n",
      "        [4.3000e+02, 0.0000e+00, 4.7917e+04, 1.2000e+02],\n",
      "        [1.2910e+03, 0.0000e+00, 4.0664e+04, 1.2000e+02],\n",
      "        [5.9670e+03, 0.0000e+00, 4.5332e+04, 1.2000e+02],\n",
      "        [7.7620e+03, 0.0000e+00, 4.6238e+04, 1.2000e+02],\n",
      "        [1.6710e+03, 0.0000e+00, 4.7147e+04, 1.2000e+02],\n",
      "        [5.4860e+03, 0.0000e+00, 4.5541e+04, 1.2000e+02],\n",
      "        [2.1700e+02, 0.0000e+00, 4.6721e+04, 1.2000e+02],\n",
      "        [2.5170e+03, 0.0000e+00, 4.3567e+04, 1.2000e+02],\n",
      "        [7.5360e+03, 0.0000e+00, 3.4915e+04, 1.2000e+02],\n",
      "        [5.0000e+00, 0.0000e+00, 4.7474e+04, 1.2000e+02],\n",
      "        [2.4100e+02, 0.0000e+00, 4.7577e+04, 1.2000e+02],\n",
      "        [2.9800e+02, 0.0000e+00, 3.8968e+04, 1.2000e+02],\n",
      "        [7.5150e+03, 0.0000e+00, 4.7520e+04, 1.2000e+02],\n",
      "        [2.6750e+03, 0.0000e+00, 4.3620e+04, 1.2000e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)}), (tensor([[[ -34.4934,  -34.8867,  -34.6139,  ...,  -41.1821,  -44.6775,\n",
      "           -38.2799],\n",
      "         [ -40.9303,  -35.8673,  -37.4658,  ...,  -38.2229,  -44.2371,\n",
      "           -44.9675],\n",
      "         [ -41.7078,  -46.5255,  -47.3779,  ...,  -36.2947,  -40.2023,\n",
      "           -37.6907],\n",
      "         ...,\n",
      "         [ -80.5832,  -98.8488,  -85.8871,  ..., -101.6588,  -91.4439,\n",
      "           -79.8061],\n",
      "         [ -97.5626,  -78.6539,  -82.9261,  ...,  -88.7666, -104.6133,\n",
      "          -103.0598],\n",
      "         [ -85.1035,  -79.0904,  -88.8686,  ...,  -87.3066,  -95.1801,\n",
      "           -82.1040]]]), {'boxes': tensor([[  252.,     0., 32498.,   120.],\n",
      "        [19343.,     0., 47587.,   120.],\n",
      "        [ 5415.,     0., 31086.,   120.],\n",
      "        [21454.,     0., 40542.,   120.],\n",
      "        [ 3751.,     0., 46807.,   120.],\n",
      "        [ 1491.,     0., 47627.,   120.],\n",
      "        [ 6017.,     0., 44629.,   120.],\n",
      "        [ 5722.,     0., 47280.,   120.],\n",
      "        [ 4630.,     0., 46770.,   120.],\n",
      "        [ 5129.,     0., 46587.,   120.],\n",
      "        [ 1821.,     0., 45984.,   120.],\n",
      "        [  371.,     0., 43733.,   120.],\n",
      "        [   68.,     0., 45167.,   120.],\n",
      "        [  961.,     0., 47901.,   120.],\n",
      "        [ 1990.,     0., 40981.,   120.],\n",
      "        [ 4068.,     0., 44870.,   120.],\n",
      "        [ 2371.,     0., 44930.,   120.],\n",
      "        [ 4128.,     0., 45051.,   120.],\n",
      "        [ 1306.,     0., 43842.,   120.],\n",
      "        [ 1801.,     0., 44546.,   120.],\n",
      "        [ 1701.,     0., 47130.,   120.],\n",
      "        [ 5079.,     0., 45159.,   120.],\n",
      "        [ 3268.,     0., 46292.,   120.],\n",
      "        [ 1903.,     0., 47892.,   120.],\n",
      "        [ 2626.,     0., 45701.,   120.],\n",
      "        [ 3380.,     0., 47587.,   120.],\n",
      "        [ 2203.,     0., 46649.,   120.],\n",
      "        [ 1788.,     0., 45171.,   120.],\n",
      "        [    0.,     0.,     0.,     0.],\n",
      "        [    0.,     0.,     0.,     0.],\n",
      "        [    0.,     0.,     0.,     0.],\n",
      "        [    0.,     0.,     0.,     0.]]), 'labels': tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)}), (tensor([[[ -53.8197,  -57.0277,  -53.9671,  ...,  -59.3862,  -59.4244,\n",
      "           -55.3926],\n",
      "         [ -56.1772,  -51.9787,  -47.6228,  ...,  -57.9860,  -64.4110,\n",
      "           -50.5492],\n",
      "         [ -58.8052,  -55.1585,  -47.5808,  ...,  -70.5284,  -53.0340,\n",
      "           -56.7050],\n",
      "         ...,\n",
      "         [ -85.7583,  -88.1996,  -93.2839,  ...,  -96.8071,  -79.2810,\n",
      "           -75.6310],\n",
      "         [ -88.7708,  -90.9349,  -91.9786,  ...,  -92.0614,  -88.1807,\n",
      "           -79.2606],\n",
      "         [ -88.6678,  -93.9322,  -89.6991,  ...,  -86.2445, -101.6584,\n",
      "           -81.4428]]]), {'boxes': tensor([[2.0380e+04, 0.0000e+00, 3.8543e+04, 1.2000e+02],\n",
      "        [6.5800e+02, 0.0000e+00, 3.0742e+04, 1.2000e+02],\n",
      "        [1.1508e+04, 0.0000e+00, 4.7327e+04, 1.2000e+02],\n",
      "        [1.6279e+04, 0.0000e+00, 4.4563e+04, 1.2000e+02],\n",
      "        [4.7100e+03, 0.0000e+00, 3.2116e+04, 1.2000e+02],\n",
      "        [1.4100e+02, 0.0000e+00, 4.6010e+04, 1.2000e+02],\n",
      "        [1.1800e+02, 0.0000e+00, 4.7676e+04, 1.2000e+02],\n",
      "        [6.9600e+02, 0.0000e+00, 4.7824e+04, 1.2000e+02],\n",
      "        [3.0000e+01, 0.0000e+00, 4.7238e+04, 1.2000e+02],\n",
      "        [2.5660e+03, 0.0000e+00, 4.5214e+04, 1.2000e+02],\n",
      "        [4.5550e+03, 0.0000e+00, 4.6994e+04, 1.2000e+02],\n",
      "        [2.0300e+02, 0.0000e+00, 4.6892e+04, 1.2000e+02],\n",
      "        [1.5870e+03, 0.0000e+00, 4.7284e+04, 1.2000e+02],\n",
      "        [2.8830e+03, 0.0000e+00, 4.7486e+04, 1.2000e+02],\n",
      "        [2.4720e+03, 0.0000e+00, 4.6689e+04, 1.2000e+02],\n",
      "        [7.1100e+02, 0.0000e+00, 4.6719e+04, 1.2000e+02],\n",
      "        [2.6010e+03, 0.0000e+00, 4.7051e+04, 1.2000e+02],\n",
      "        [1.5180e+03, 0.0000e+00, 4.7520e+04, 1.2000e+02],\n",
      "        [3.6000e+01, 0.0000e+00, 4.7326e+04, 1.2000e+02],\n",
      "        [6.9530e+03, 0.0000e+00, 4.7168e+04, 1.2000e+02],\n",
      "        [1.5000e+02, 0.0000e+00, 4.5070e+04, 1.2000e+02],\n",
      "        [3.6600e+02, 0.0000e+00, 4.7646e+04, 1.2000e+02],\n",
      "        [3.2900e+02, 0.0000e+00, 4.7214e+04, 1.2000e+02],\n",
      "        [5.0620e+03, 0.0000e+00, 4.5533e+04, 1.2000e+02],\n",
      "        [1.1560e+03, 0.0000e+00, 4.5720e+04, 1.2000e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]), 'labels': tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)}), (tensor([[[-51.5806, -77.7975, -59.7446,  ..., -65.3796, -56.4950, -50.7783],\n",
      "         [-50.1405, -57.3663, -58.6644,  ..., -51.9789, -50.9430, -48.2857],\n",
      "         [-55.9827, -59.0238, -50.1395,  ..., -49.9105, -52.6785, -50.8440],\n",
      "         ...,\n",
      "         [-77.2540, -87.9298, -79.1659,  ..., -67.9447, -71.0204, -88.5922],\n",
      "         [-79.9338, -88.6045, -78.1126,  ..., -72.7548, -71.5493, -70.3543],\n",
      "         [-79.1128, -82.2741, -81.8147,  ..., -75.1189, -77.0639, -68.8405]]]), {'boxes': tensor([[4.1400e+02, 0.0000e+00, 3.1109e+04, 1.2000e+02],\n",
      "        [1.3186e+04, 0.0000e+00, 4.7124e+04, 1.2000e+02],\n",
      "        [1.9985e+04, 0.0000e+00, 4.1887e+04, 1.2000e+02],\n",
      "        [8.2980e+03, 0.0000e+00, 4.1528e+04, 1.2000e+02],\n",
      "        [1.7330e+03, 0.0000e+00, 3.1508e+04, 1.2000e+02],\n",
      "        [1.6720e+03, 0.0000e+00, 4.5292e+04, 1.2000e+02],\n",
      "        [2.9890e+03, 0.0000e+00, 4.6457e+04, 1.2000e+02],\n",
      "        [2.4000e+02, 0.0000e+00, 4.6812e+04, 1.2000e+02],\n",
      "        [3.6740e+03, 0.0000e+00, 4.6370e+04, 1.2000e+02],\n",
      "        [2.2000e+01, 0.0000e+00, 4.7958e+04, 1.2000e+02],\n",
      "        [5.8640e+03, 0.0000e+00, 4.6105e+04, 1.2000e+02],\n",
      "        [1.5250e+03, 0.0000e+00, 4.5945e+04, 1.2000e+02],\n",
      "        [1.9300e+02, 0.0000e+00, 4.4524e+04, 1.2000e+02],\n",
      "        [6.6240e+03, 0.0000e+00, 4.6127e+04, 1.2000e+02],\n",
      "        [4.0970e+03, 0.0000e+00, 4.6994e+04, 1.2000e+02],\n",
      "        [2.1900e+02, 0.0000e+00, 4.6523e+04, 1.2000e+02],\n",
      "        [1.7690e+03, 0.0000e+00, 4.3238e+04, 1.2000e+02],\n",
      "        [3.3300e+02, 0.0000e+00, 4.7857e+04, 1.2000e+02],\n",
      "        [1.4000e+01, 0.0000e+00, 4.5337e+04, 1.2000e+02],\n",
      "        [4.4510e+03, 0.0000e+00, 4.6841e+04, 1.2000e+02],\n",
      "        [2.6600e+02, 0.0000e+00, 3.9028e+04, 1.2000e+02],\n",
      "        [2.8600e+02, 0.0000e+00, 4.6295e+04, 1.2000e+02],\n",
      "        [2.3800e+02, 0.0000e+00, 4.6861e+04, 1.2000e+02],\n",
      "        [7.2200e+02, 0.0000e+00, 4.3354e+04, 1.2000e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]), 'labels': tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)}), (tensor([[[-33.1513, -31.6426, -33.0769,  ..., -34.8136, -37.4398, -41.3537],\n",
      "         [-36.0400, -35.8086, -35.9357,  ..., -39.6223, -37.5163, -47.5044],\n",
      "         [-47.2830, -45.9989, -44.6731,  ..., -50.8299, -47.7687, -40.0039],\n",
      "         ...,\n",
      "         [-91.3385, -92.9452, -86.7364,  ..., -87.9500, -85.8145, -89.1274],\n",
      "         [-86.0738, -83.6073, -88.6823,  ..., -83.3926, -84.9165, -94.1442],\n",
      "         [-85.5404, -79.6145, -95.2414,  ..., -85.4285, -91.3270, -85.3135]]]), {'boxes': tensor([[5.4350e+03, 0.0000e+00, 3.7382e+04, 1.2000e+02],\n",
      "        [3.7190e+03, 0.0000e+00, 3.2950e+04, 1.2000e+02],\n",
      "        [2.9730e+03, 0.0000e+00, 2.4352e+04, 1.2000e+02],\n",
      "        [2.5340e+03, 0.0000e+00, 3.4097e+04, 1.2000e+02],\n",
      "        [3.9980e+03, 0.0000e+00, 4.3066e+04, 1.2000e+02],\n",
      "        [1.0300e+03, 0.0000e+00, 4.3084e+04, 1.2000e+02],\n",
      "        [5.6000e+01, 0.0000e+00, 4.3453e+04, 1.2000e+02],\n",
      "        [3.4550e+03, 0.0000e+00, 4.6516e+04, 1.2000e+02],\n",
      "        [3.8950e+03, 0.0000e+00, 4.5654e+04, 1.2000e+02],\n",
      "        [2.0690e+03, 0.0000e+00, 4.7630e+04, 1.2000e+02],\n",
      "        [2.8600e+02, 0.0000e+00, 4.1951e+04, 1.2000e+02],\n",
      "        [1.0160e+03, 0.0000e+00, 4.1493e+04, 1.2000e+02],\n",
      "        [6.1700e+02, 0.0000e+00, 3.9091e+04, 1.2000e+02],\n",
      "        [5.7810e+03, 0.0000e+00, 4.5323e+04, 1.2000e+02],\n",
      "        [4.6800e+02, 0.0000e+00, 4.6636e+04, 1.2000e+02],\n",
      "        [6.0760e+03, 0.0000e+00, 4.7459e+04, 1.2000e+02],\n",
      "        [3.9410e+03, 0.0000e+00, 4.5201e+04, 1.2000e+02],\n",
      "        [1.0000e+02, 0.0000e+00, 4.7883e+04, 1.2000e+02],\n",
      "        [7.9720e+03, 0.0000e+00, 4.7971e+04, 1.2000e+02],\n",
      "        [1.2890e+03, 0.0000e+00, 4.7617e+04, 1.2000e+02],\n",
      "        [2.7000e+01, 0.0000e+00, 4.7117e+04, 1.2000e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]), 'labels': tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)}), (tensor([[[-40.1218, -42.0941, -44.4621,  ..., -44.4637, -45.1264, -40.5232],\n",
      "         [-43.5396, -49.7375, -46.5745,  ..., -42.4952, -50.3227, -41.8831],\n",
      "         [-54.3506, -47.5871, -49.5232,  ..., -46.8527, -45.1900, -47.5534],\n",
      "         ...,\n",
      "         [-62.7652, -69.5858, -65.7503,  ..., -72.1814, -72.9841, -71.0849],\n",
      "         [-63.9793, -63.5566, -73.2880,  ..., -75.4213, -65.2495, -65.5999],\n",
      "         [-67.5979, -69.0726, -76.2065,  ..., -71.2522, -63.6882, -65.9521]]]), {'boxes': tensor([[15215.,     0., 45279.,   120.],\n",
      "        [ 5081.,     0., 30277.,   120.],\n",
      "        [ 4907.,     0., 40356.,   120.],\n",
      "        [ 7793.,     0., 47282.,   120.],\n",
      "        [ 6698.,     0., 45290.,   120.],\n",
      "        [13817.,     0., 36150.,   120.],\n",
      "        [17977.,     0., 47429.,   120.],\n",
      "        [ 7099.,     0., 47246.,   120.],\n",
      "        [ 1455.,     0., 47972.,   120.],\n",
      "        [ 4346.,     0., 44707.,   120.],\n",
      "        [  378.,     0., 47566.,   120.],\n",
      "        [  797.,     0., 47076.,   120.],\n",
      "        [  446.,     0., 47099.,   120.],\n",
      "        [   85.,     0., 46810.,   120.],\n",
      "        [ 8397.,     0., 47065.,   120.],\n",
      "        [  340.,     0., 44856.,   120.],\n",
      "        [ 1390.,     0., 41389.,   120.],\n",
      "        [ 1905.,     0., 46593.,   120.],\n",
      "        [  389.,     0., 46549.,   120.],\n",
      "        [  507.,     0., 47429.,   120.],\n",
      "        [ 6038.,     0., 47980.,   120.],\n",
      "        [ 3848.,     0., 46264.,   120.],\n",
      "        [  723.,     0., 41931.,   120.],\n",
      "        [  135.,     0., 47886.,   120.],\n",
      "        [    0.,     0.,     0.,     0.],\n",
      "        [    0.,     0.,     0.,     0.],\n",
      "        [    0.,     0.,     0.,     0.],\n",
      "        [    0.,     0.,     0.,     0.],\n",
      "        [    0.,     0.,     0.,     0.],\n",
      "        [    0.,     0.,     0.,     0.],\n",
      "        [    0.,     0.,     0.,     0.],\n",
      "        [    0.,     0.,     0.,     0.]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)}), (tensor([[[ -58.1816,  -51.4133,  -55.2925,  ...,  -60.3654,  -63.5809,\n",
      "           -54.5406],\n",
      "         [ -52.8478,  -54.3121,  -57.7920,  ...,  -60.8342,  -58.3028,\n",
      "           -57.2821],\n",
      "         [ -54.8402,  -59.0959,  -88.9596,  ...,  -59.6751,  -59.3296,\n",
      "           -59.7923],\n",
      "         ...,\n",
      "         [-104.5512,  -97.1758,  -96.9660,  ..., -102.4221,  -99.9494,\n",
      "          -105.1544],\n",
      "         [-101.9377,  -95.9157, -110.0231,  ...,  -93.8056,  -93.8486,\n",
      "           -95.7082],\n",
      "         [ -95.7276,  -90.5936,  -99.9502,  ...,  -93.7600,  -93.8583,\n",
      "           -97.9210]]]), {'boxes': tensor([[1.8080e+04, 0.0000e+00, 4.4393e+04, 1.2000e+02],\n",
      "        [1.1069e+04, 0.0000e+00, 3.6602e+04, 1.2000e+02],\n",
      "        [2.3486e+04, 0.0000e+00, 4.6882e+04, 1.2000e+02],\n",
      "        [1.0387e+04, 0.0000e+00, 4.2895e+04, 1.2000e+02],\n",
      "        [2.8720e+03, 0.0000e+00, 4.6196e+04, 1.2000e+02],\n",
      "        [1.7350e+03, 0.0000e+00, 4.7963e+04, 1.2000e+02],\n",
      "        [3.4880e+03, 0.0000e+00, 4.7212e+04, 1.2000e+02],\n",
      "        [2.1690e+03, 0.0000e+00, 2.7147e+04, 1.2000e+02],\n",
      "        [6.3620e+03, 0.0000e+00, 4.4796e+04, 1.2000e+02],\n",
      "        [2.0070e+03, 0.0000e+00, 4.7663e+04, 1.2000e+02],\n",
      "        [6.8500e+03, 0.0000e+00, 4.5876e+04, 1.2000e+02],\n",
      "        [2.1000e+01, 0.0000e+00, 4.7968e+04, 1.2000e+02],\n",
      "        [2.4920e+03, 0.0000e+00, 4.7558e+04, 1.2000e+02],\n",
      "        [9.2700e+02, 0.0000e+00, 3.9773e+04, 1.2000e+02],\n",
      "        [1.8440e+03, 0.0000e+00, 4.7380e+04, 1.2000e+02],\n",
      "        [3.3150e+03, 0.0000e+00, 4.6124e+04, 1.2000e+02],\n",
      "        [4.7410e+03, 0.0000e+00, 4.5619e+04, 1.2000e+02],\n",
      "        [2.0940e+03, 0.0000e+00, 4.7750e+04, 1.2000e+02],\n",
      "        [2.1300e+03, 0.0000e+00, 4.4534e+04, 1.2000e+02],\n",
      "        [1.5900e+02, 0.0000e+00, 4.6959e+04, 1.2000e+02],\n",
      "        [5.9800e+02, 0.0000e+00, 4.5903e+04, 1.2000e+02],\n",
      "        [5.7420e+03, 0.0000e+00, 4.4522e+04, 1.2000e+02],\n",
      "        [1.8500e+03, 0.0000e+00, 4.1764e+04, 1.2000e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]), 'labels': tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)}), (tensor([[[-48.6319, -40.5747, -36.1603,  ..., -38.9456, -40.2740, -36.0428],\n",
      "         [-39.7844, -36.3227, -39.1892,  ..., -37.1809, -39.0878, -39.4695],\n",
      "         [-38.6713, -38.9160, -45.9279,  ..., -37.6173, -40.4763, -48.6406],\n",
      "         ...,\n",
      "         [-89.8751, -84.2710, -88.4831,  ..., -84.3718, -81.1653, -85.5942],\n",
      "         [-88.5000, -94.2719, -86.1289,  ..., -89.3220, -79.9606, -97.0994],\n",
      "         [-80.3422, -94.8875, -92.9999,  ..., -92.7915, -80.1132, -90.3738]]]), {'boxes': tensor([[4.3270e+03, 0.0000e+00, 3.9077e+04, 1.2000e+02],\n",
      "        [1.4262e+04, 0.0000e+00, 3.1652e+04, 1.2000e+02],\n",
      "        [8.0920e+03, 0.0000e+00, 3.1147e+04, 1.2000e+02],\n",
      "        [1.0632e+04, 0.0000e+00, 3.9295e+04, 1.2000e+02],\n",
      "        [1.4210e+03, 0.0000e+00, 4.0332e+04, 1.2000e+02],\n",
      "        [2.9160e+03, 0.0000e+00, 4.5669e+04, 1.2000e+02],\n",
      "        [6.4700e+02, 0.0000e+00, 4.7174e+04, 1.2000e+02],\n",
      "        [3.0600e+02, 0.0000e+00, 4.5698e+04, 1.2000e+02],\n",
      "        [1.9500e+02, 0.0000e+00, 4.6547e+04, 1.2000e+02],\n",
      "        [3.5150e+03, 0.0000e+00, 4.3080e+04, 1.2000e+02],\n",
      "        [2.3860e+03, 0.0000e+00, 4.7739e+04, 1.2000e+02],\n",
      "        [3.1530e+03, 0.0000e+00, 4.6588e+04, 1.2000e+02],\n",
      "        [1.2490e+03, 0.0000e+00, 4.5857e+04, 1.2000e+02],\n",
      "        [3.9470e+03, 0.0000e+00, 4.7042e+04, 1.2000e+02],\n",
      "        [5.8700e+02, 0.0000e+00, 4.5703e+04, 1.2000e+02],\n",
      "        [3.5820e+03, 0.0000e+00, 4.4088e+04, 1.2000e+02],\n",
      "        [2.1300e+03, 0.0000e+00, 4.7179e+04, 1.2000e+02],\n",
      "        [1.3000e+01, 0.0000e+00, 4.7998e+04, 1.2000e+02],\n",
      "        [4.9100e+02, 0.0000e+00, 3.9054e+04, 1.2000e+02],\n",
      "        [2.1700e+02, 0.0000e+00, 4.4646e+04, 1.2000e+02],\n",
      "        [1.3670e+03, 0.0000e+00, 4.3525e+04, 1.2000e+02],\n",
      "        [3.5930e+03, 0.0000e+00, 4.2724e+04, 1.2000e+02],\n",
      "        [7.9000e+01, 0.0000e+00, 4.7141e+04, 1.2000e+02],\n",
      "        [2.4390e+03, 0.0000e+00, 4.2891e+04, 1.2000e+02],\n",
      "        [4.4000e+02, 0.0000e+00, 3.9836e+04, 1.2000e+02],\n",
      "        [2.2290e+03, 0.0000e+00, 4.5740e+04, 1.2000e+02],\n",
      "        [3.7900e+02, 0.0000e+00, 4.7862e+04, 1.2000e+02],\n",
      "        [4.6820e+03, 0.0000e+00, 4.7380e+04, 1.2000e+02],\n",
      "        [1.7200e+02, 0.0000e+00, 4.7689e+04, 1.2000e+02],\n",
      "        [1.9700e+02, 0.0000e+00, 4.7996e+04, 1.2000e+02],\n",
      "        [1.7010e+03, 0.0000e+00, 4.4511e+04, 1.2000e+02],\n",
      "        [2.1400e+02, 0.0000e+00, 4.3530e+04, 1.2000e+02]]), 'labels': tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)}), (tensor([[[ -46.9170,  -50.0456,  -48.3165,  ...,  -50.0076,  -51.6813,\n",
      "           -57.9834],\n",
      "         [ -42.6830,  -49.4470,  -47.0226,  ...,  -41.6272,  -43.7213,\n",
      "           -49.7972],\n",
      "         [ -47.6015,  -58.2832,  -49.0143,  ...,  -41.8040,  -50.7360,\n",
      "           -47.2466],\n",
      "         ...,\n",
      "         [ -87.2291,  -93.1094,  -86.2337,  ...,  -93.8290,  -85.8743,\n",
      "           -84.9396],\n",
      "         [ -89.7792,  -96.8532,  -87.8309,  ...,  -98.2387,  -91.2832,\n",
      "           -89.1015],\n",
      "         [ -94.6079,  -89.9196,  -86.4386,  ..., -100.1926, -100.2213,\n",
      "           -92.6908]]]), {'boxes': tensor([[17194.,     0., 47786.,   120.],\n",
      "        [ 3533.,     0., 34908.,   120.],\n",
      "        [ 2735.,     0., 33845.,   120.],\n",
      "        [24373.,     0., 42303.,   120.],\n",
      "        [ 3924.,     0., 46575.,   120.],\n",
      "        [19465.,     0., 45296.,   120.],\n",
      "        [21513.,     0., 46891.,   120.],\n",
      "        [ 6591.,     0., 45031.,   120.],\n",
      "        [  224.,     0., 43838.,   120.],\n",
      "        [ 1455.,     0., 47986.,   120.],\n",
      "        [ 4107.,     0., 46588.,   120.],\n",
      "        [ 1995.,     0., 45936.,   120.],\n",
      "        [   56.,     0., 47879.,   120.],\n",
      "        [  343.,     0., 44617.,   120.],\n",
      "        [ 5846.,     0., 47479.,   120.],\n",
      "        [  873.,     0., 41274.,   120.],\n",
      "        [  614.,     0., 46394.,   120.],\n",
      "        [  883.,     0., 46348.,   120.],\n",
      "        [  699.,     0., 47451.,   120.],\n",
      "        [  524.,     0., 47883.,   120.],\n",
      "        [ 4619.,     0., 47244.,   120.],\n",
      "        [  613.,     0., 44415.,   120.],\n",
      "        [  101.,     0., 41022.,   120.],\n",
      "        [ 3445.,     0., 46653.,   120.],\n",
      "        [  148.,     0., 45385.,   120.],\n",
      "        [ 3547.,     0., 47517.,   120.],\n",
      "        [ 5116.,     0., 45706.,   120.],\n",
      "        [ 4121.,     0., 45281.,   120.],\n",
      "        [ 1103.,     0., 46620.,   120.],\n",
      "        [ 2494.,     0., 46527.,   120.],\n",
      "        [    0.,     0.,     0.,     0.],\n",
      "        [    0.,     0.,     0.,     0.]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)}), (tensor([[[-63.0123, -56.6265, -54.5136,  ..., -78.4007, -63.4013, -57.2393],\n",
      "         [-64.1590, -56.1294, -53.9822,  ..., -68.4172, -59.5200, -62.8507],\n",
      "         [-68.5299, -57.1210, -54.4939,  ..., -65.9210, -61.6523, -64.4208],\n",
      "         ...,\n",
      "         [-91.2763, -96.6720, -87.4964,  ..., -87.8266, -90.5154, -91.8216],\n",
      "         [-94.3822, -90.2701, -84.1901,  ..., -92.9646, -88.9574, -86.1141],\n",
      "         [-89.1895, -86.8180, -84.8085,  ..., -93.4638, -89.4497, -85.5744]]]), {'boxes': tensor([[2.2218e+04, 0.0000e+00, 4.7672e+04, 1.2000e+02],\n",
      "        [1.7545e+04, 0.0000e+00, 4.1410e+04, 1.2000e+02],\n",
      "        [1.1600e+04, 0.0000e+00, 4.2724e+04, 1.2000e+02],\n",
      "        [1.8940e+03, 0.0000e+00, 3.5671e+04, 1.2000e+02],\n",
      "        [1.8606e+04, 0.0000e+00, 4.3081e+04, 1.2000e+02],\n",
      "        [8.4770e+03, 0.0000e+00, 3.8729e+04, 1.2000e+02],\n",
      "        [2.5694e+04, 0.0000e+00, 4.7306e+04, 1.2000e+02],\n",
      "        [5.3690e+03, 0.0000e+00, 3.2154e+04, 1.2000e+02],\n",
      "        [3.6120e+03, 0.0000e+00, 2.4677e+04, 1.2000e+02],\n",
      "        [3.5450e+03, 0.0000e+00, 2.7714e+04, 1.2000e+02],\n",
      "        [4.1020e+03, 0.0000e+00, 3.4817e+04, 1.2000e+02],\n",
      "        [2.6000e+02, 0.0000e+00, 4.3771e+04, 1.2000e+02],\n",
      "        [2.5020e+03, 0.0000e+00, 4.6221e+04, 1.2000e+02],\n",
      "        [5.4660e+03, 0.0000e+00, 4.5350e+04, 1.2000e+02],\n",
      "        [1.3000e+01, 0.0000e+00, 4.4901e+04, 1.2000e+02],\n",
      "        [6.6400e+02, 0.0000e+00, 4.6788e+04, 1.2000e+02],\n",
      "        [1.7220e+03, 0.0000e+00, 4.4505e+04, 1.2000e+02],\n",
      "        [4.7410e+03, 0.0000e+00, 4.7948e+04, 1.2000e+02],\n",
      "        [4.8880e+03, 0.0000e+00, 4.7978e+04, 1.2000e+02],\n",
      "        [2.5914e+04, 0.0000e+00, 4.3556e+04, 1.2000e+02],\n",
      "        [3.4580e+03, 0.0000e+00, 4.6607e+04, 1.2000e+02],\n",
      "        [4.1310e+03, 0.0000e+00, 4.2841e+04, 1.2000e+02],\n",
      "        [4.9620e+03, 0.0000e+00, 4.5413e+04, 1.2000e+02],\n",
      "        [1.7990e+03, 0.0000e+00, 4.1606e+04, 1.2000e+02],\n",
      "        [7.7780e+03, 0.0000e+00, 4.7883e+04, 1.2000e+02],\n",
      "        [6.9950e+03, 0.0000e+00, 4.6393e+04, 1.2000e+02],\n",
      "        [1.0830e+03, 0.0000e+00, 4.7939e+04, 1.2000e+02],\n",
      "        [5.9380e+03, 0.0000e+00, 4.5171e+04, 1.2000e+02],\n",
      "        [4.4400e+02, 0.0000e+00, 4.2927e+04, 1.2000e+02],\n",
      "        [5.2950e+03, 0.0000e+00, 4.3717e+04, 1.2000e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)}), (tensor([[[ -46.8114,  -46.5708,  -51.0824,  ...,  -52.5302,  -52.5606,\n",
      "           -52.4862],\n",
      "         [ -52.0531,  -43.6302,  -53.8831,  ...,  -50.3308,  -58.1993,\n",
      "           -48.6813],\n",
      "         [ -71.5364,  -51.7475,  -46.1800,  ...,  -47.0502,  -51.3480,\n",
      "           -48.5677],\n",
      "         ...,\n",
      "         [ -83.3769,  -90.4766,  -84.5947,  ...,  -79.6923,  -86.5084,\n",
      "           -79.6208],\n",
      "         [ -88.3533,  -82.4615,  -89.1746,  ...,  -83.3282,  -87.1053,\n",
      "           -76.5380],\n",
      "         [ -85.0186,  -86.7712, -102.1948,  ...,  -83.6986,  -84.9691,\n",
      "           -78.5439]]]), {'boxes': tensor([[ 6224.,     0., 21044.,   120.],\n",
      "        [  464.,     0., 24430.,   120.],\n",
      "        [ 6236.,     0., 36296.,   120.],\n",
      "        [ 6281.,     0., 46172.,   120.],\n",
      "        [ 3932.,     0., 47755.,   120.],\n",
      "        [   64.,     0., 47742.,   120.],\n",
      "        [ 3030.,     0., 46535.,   120.],\n",
      "        [ 3343.,     0., 47546.,   120.],\n",
      "        [  127.,     0., 47912.,   120.],\n",
      "        [  394.,     0., 46758.,   120.],\n",
      "        [ 5886.,     0., 46140.,   120.],\n",
      "        [ 2482.,     0., 41398.,   120.],\n",
      "        [ 5733.,     0., 46289.,   120.],\n",
      "        [ 1289.,     0., 46643.,   120.],\n",
      "        [ 1478.,     0., 41496.,   120.],\n",
      "        [ 5037.,     0., 46580.,   120.],\n",
      "        [  497.,     0., 46372.,   120.],\n",
      "        [ 2717.,     0., 45093.,   120.],\n",
      "        [ 4525.,     0., 45572.,   120.],\n",
      "        [ 1740.,     0., 43728.,   120.],\n",
      "        [ 5129.,     0., 45189.,   120.],\n",
      "        [    0.,     0.,     0.,     0.],\n",
      "        [    0.,     0.,     0.,     0.],\n",
      "        [    0.,     0.,     0.,     0.],\n",
      "        [    0.,     0.,     0.,     0.],\n",
      "        [    0.,     0.,     0.,     0.],\n",
      "        [    0.,     0.,     0.,     0.],\n",
      "        [    0.,     0.,     0.,     0.],\n",
      "        [    0.,     0.,     0.,     0.],\n",
      "        [    0.,     0.,     0.,     0.],\n",
      "        [    0.,     0.,     0.,     0.],\n",
      "        [    0.,     0.,     0.,     0.]]), 'labels': tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)})]\n"
     ]
    }
   ],
   "source": [
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "# def transform_audio(data):\n",
    "#     _, _, specto = compute_spectrogram(data, 24000, nperseg=256, noverlap=256/2, scale=\"dB\")\n",
    "#     # freq clip\n",
    "#     specto = specto[:120, :]\n",
    "#     return specto\n",
    "\n",
    "# def padding_collate(batch):\n",
    "#     nbatch, image_list, boxes_list, labels_list = [], [], [], []\n",
    "#     for data in batch:\n",
    "#         image_list.append(data[0])\n",
    "#         boxes_list.append(data[1])\n",
    "#         labels_list.append(data[2])\n",
    "#     boxes_list=pad_sequence(boxes_list, batch_first=True)\n",
    "#     labels_list=pad_sequence(labels_list, batch_first=True)\n",
    "#     for i in range(len(image_list)):\n",
    "#         nbatch.append((image_list[i], {'boxes':boxes_list[i], 'labels':labels_list[i]}))\n",
    "#     return nbatch\n",
    "\n",
    "# detection_dataloader = torch.utils.data.DataLoader(OneShotDataset(detection_dir=path_utils.get_detection_data_path(),\n",
    "#                                                     transform_audio=transform_audio, device=device),collate_fn=padding_collate,batch_size=16)\n",
    "# for data in detection_dataloader:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def rcnn_pretrained_backbone(num_classes : int, anchor_sizes : tuple, aspect_ratios : tuple, parameters : dict = {}):\n",
    "#     \"\"\"\n",
    "#     Return a faster rcnn with a mobilenetv3 backbone.\n",
    "\n",
    "#     Args:\n",
    "#         num_classes (int): Number of classes expected to return (background should be taken into account)\n",
    "#         parameters (dict, optional): Dictionnary for the different following parameters. Defaults to {}.\n",
    "\n",
    "#     Returns:\n",
    "#         (torchvision.models.detection.faster_rcnn.FasterRCNN): Model implementation of pytorch\n",
    "\n",
    "#     >>> training\n",
    "#     # RPN\n",
    "#     rpn_pre_nms_top_n_train (int): number of proposals to keep before applying NMS during training\n",
    "#     rpn_post_nms_top_n_train (int): number of proposals to keep after applying NMS during training\n",
    "#     rpn_fg_iou_thresh (float): minimum IoU between the anchor and the GT box so that they can be\n",
    "#         considered as positive during training of the RPN.\n",
    "#     rpn_bg_iou_thresh (float): maximum IoU between the anchor and the GT box so that they can be\n",
    "#         considered as negative during training of the RPN.\n",
    "#     rpn_batch_size_per_image (int): number of anchors that are sampled during training of the RPN\n",
    "#         for computing the loss\n",
    "#     rpn_positive_fraction (float): proportion of positive anchors in a mini-batch during training\n",
    "#         of the RPN\n",
    "\n",
    "#     # Head\n",
    "#     box_fg_iou_thresh (float): minimum IoU between the proposals and the GT box so that they can be\n",
    "#         considered as positive during training of the classification head\n",
    "#     box_bg_iou_thresh (float): maximum IoU between the proposals and the GT box so that they can be\n",
    "#         considered as negative during training of the classification head\n",
    "#     box_batch_size_per_image (int): number of proposals that are sampled during training of the\n",
    "#         classification head\n",
    "#     box_positive_fraction (float): proportion of positive proposals in a mini-batch during training\n",
    "#         of the classification head\n",
    "\n",
    "\n",
    "\n",
    "#     >>> inference\n",
    "#     # RPN\n",
    "#     rpn_pre_nms_top_n_test (int): number of proposals to keep before applying NMS during testing\n",
    "#     rpn_post_nms_top_n_test (int): number of proposals to keep after applying NMS during testing\n",
    "#     rpn_score_thresh (float): during inference, only return proposals with a classification score\n",
    "#         greater than rpn_score_thresh\n",
    "#     rpn_nms_thresh (float): NMS threshold used for postprocessing the RPN proposals\n",
    "\n",
    "#     # Head\n",
    "#     box_score_thresh (float): during inference, only return proposals with a classification score\n",
    "#         greater than box_score_thresh\n",
    "\n",
    "#     box_nms_thresh (float): NMS threshold for the prediction head. Used during inference\n",
    "#     box_detections_per_img (int): maximum number of detections per image, for all classes.\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     pretrained_backbone=True\n",
    "#     trainable_backbone_layers=6 # All backbone is trainable\n",
    "\n",
    "#     backbone = mobilenet_backbone(\"mobilenet_v3_large\", pretrained_backbone, True, trainable_layers=trainable_backbone_layers)\n",
    "\n",
    "#     model = torchvision.models.detection.faster_rcnn.FasterRCNN(backbone,\n",
    "#                                                                 num_classes,\n",
    "#                                                                 rpn_anchor_generator=AnchorGenerator(anchor_sizes, aspect_ratios),\n",
    "#                                                                 **parameters)\n",
    "\n",
    "#     # Custom transform ie no transform (only postprocessing)\n",
    "#     model.transform = GeneralizedRCNNTransform(min_size=489, max_size=2000, image_mean=[0, 0, 0], image_std=[1, 1, 1])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rcnn_pretrained_backbone_train(num_classes : int, anchor_sizes : tuple, aspect_ratios : tuple, parameters : dict = {}):\n",
    "#     \"\"\"\n",
    "#     Return a jit compiled faster rcnn with a mobilenetv3 backbone.\n",
    "#     \"\"\"\n",
    "#     model = rcnn_pretrained_backbone(num_classes, anchor_sizes, aspect_ratios, parameters)\n",
    "#     model._has_warned = True # Remove warning about \"RCNN always returns a (Losses, Detections) tuple in scripting\"\n",
    "#     return torch.jit.script(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_faster_rcnn(dict_losses : dict, training_rpn : bool, training_head : bool):\n",
    "    \"\"\" Reduce the dictionnary of losses\n",
    "\n",
    "    Args:\n",
    "        dict_losses (dict): Dictionnary of losses\n",
    "        training_rpn (bool): Bool to train the rpn\n",
    "        training_head (bool): Bool to train the head\n",
    "\n",
    "    Returns:\n",
    "        (torch.Tensor): Loss\n",
    "    \"\"\"\n",
    "    # Dict(\"loss_classifier\", \"loss_box_reg\", \"loss_objectness\", \"loss_rpn_box_reg\")\n",
    "    loss = torch.zeros((), dtype=torch.float32, device=device)\n",
    "    if training_rpn:\n",
    "        loss += dict_losses[\"loss_objectness\"]\n",
    "        loss += dict_losses[\"loss_rpn_box_reg\"]\n",
    "    if training_head:\n",
    "        loss += dict_losses[\"loss_classifier\"]\n",
    "        loss += dict_losses[\"loss_box_reg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_losses(dataloader, mean_loss):\n",
    "    mean_loss[\"loss_objectness\"] /= len(dataloader)\n",
    "    mean_loss[\"loss_rpn_box_reg\"] /= len(dataloader)\n",
    "    mean_loss[\"loss_classifier\"] /= len(dataloader)\n",
    "    mean_loss[\"loss_box_reg\"] /= len(dataloader)\n",
    "    return mean_loss\n",
    "\n",
    "def accumulate_losses(mean_loss, losses):\n",
    "    mean_loss[\"loss_objectness\"] += losses[\"loss_objectness\"].item()\n",
    "    mean_loss[\"loss_rpn_box_reg\"] += losses[\"loss_rpn_box_reg\"].item()\n",
    "    mean_loss[\"loss_classifier\"] += losses[\"loss_classifier\"].item()\n",
    "    mean_loss[\"loss_box_reg\"] += losses[\"loss_box_reg\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def transform_audio(data):\n",
    "    _, _, specto = compute_spectrogram(data, 24000, nperseg=256, noverlap=256/2, scale=\"dB\")\n",
    "    # freq clip\n",
    "    specto = specto[:120, :]\n",
    "    return specto\n",
    "\n",
    "def padding_collate(batch):\n",
    "    targets, image_list, boxes_list, labels_list = [], [], [], []\n",
    "    for data in batch:\n",
    "        image_list.append(data[0])\n",
    "        boxes_list.append(data[1])\n",
    "        labels_list.append(data[2])\n",
    "    boxes_list=pad_sequence(boxes_list, batch_first=True)\n",
    "    labels_list=pad_sequence(labels_list, batch_first=True)\n",
    "    for i in range(len(boxes_list)):\n",
    "        targets.append(( {'boxes':boxes_list[i], 'labels':labels_list[i]}))\n",
    "    return image_list, targets\n",
    "\n",
    "detection_dataloader = torch.utils.data.DataLoader(OneShotDataset(detection_dir=path_utils.get_detection_data_path(),\n",
    "                                                    transform_audio=transform_audio, device=device),collate_fn=padding_collate,batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = mobilenet_backbone(\"mobilenet_v3_large\",True, False, trainable_layers=6)\n",
    "\n",
    "model = torchvision.models.detection.faster_rcnn.FasterRCNN(backbone,\n",
    "                                                                num_classes=2,\n",
    "                                                                rpn_anchor_generator=AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n",
    "                                   aspect_ratios=((0.5, 1.0, 2.0),)))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "sgd_optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# and a learning rate scheduler which decreases the learning rate by\n",
    "# 10x every 3 epochs\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(sgd_optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)\n",
    "                                        \n",
    "loss_fn_frrcnn=lambda x:loss_faster_rcnn(x,True,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, scheduler, macro_batch=1):\n",
    "    # Initialize training\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    mean_loss = {\"loss_objectness\": 0., \"loss_rpn_box_reg\": 0., \"loss_classifier\": 0., \"loss_box_reg\": 0.}\n",
    "\n",
    "    # Iterate over the dataset\n",
    "    for batch, (X, targets) in enumerate(dataloader):\n",
    "        print(targets)\n",
    "        # Work with the GPU if available\n",
    "        X = list(x.to(device) for x in X)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        # Compute prediction error\n",
    "        losses, detections = model(X, targets)\n",
    "        accumulate_losses(mean_loss, losses)\n",
    "        loss = loss_fn(losses)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        if (batch+1) % macro_batch == 0 or batch == len(dataloader) - 1:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "\n",
    "        # Print metrics\n",
    "        if batch % 30 == 0 or batch == len(dataloader) - 1:\n",
    "            loss_value, current = loss.item(), (batch+1) * len(X)\n",
    "        print(loss_value)\n",
    "    return average_losses(dataloader, mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'boxes': tensor([[2.7266e+04, 0.0000e+00, 4.3424e+04, 1.2000e+02],\n",
      "        [4.6030e+03, 0.0000e+00, 3.4288e+04, 1.2000e+02],\n",
      "        [3.8040e+03, 0.0000e+00, 3.2598e+04, 1.2000e+02],\n",
      "        [1.7443e+04, 0.0000e+00, 4.0532e+04, 1.2000e+02],\n",
      "        [1.4340e+03, 0.0000e+00, 4.7866e+04, 1.2000e+02],\n",
      "        [3.7460e+03, 0.0000e+00, 4.2519e+04, 1.2000e+02],\n",
      "        [3.3000e+01, 0.0000e+00, 4.5554e+04, 1.2000e+02],\n",
      "        [1.3210e+03, 0.0000e+00, 4.5577e+04, 1.2000e+02],\n",
      "        [5.5680e+03, 0.0000e+00, 4.7548e+04, 1.2000e+02],\n",
      "        [9.5400e+02, 0.0000e+00, 4.6437e+04, 1.2000e+02],\n",
      "        [4.0010e+03, 0.0000e+00, 4.7878e+04, 1.2000e+02],\n",
      "        [3.0550e+03, 0.0000e+00, 4.6864e+04, 1.2000e+02],\n",
      "        [5.0000e+00, 0.0000e+00, 4.7919e+04, 1.2000e+02],\n",
      "        [2.9250e+03, 0.0000e+00, 4.6390e+04, 1.2000e+02],\n",
      "        [3.6800e+02, 0.0000e+00, 4.7444e+04, 1.2000e+02],\n",
      "        [6.2850e+03, 0.0000e+00, 4.6449e+04, 1.2000e+02],\n",
      "        [5.1960e+03, 0.0000e+00, 4.7987e+04, 1.2000e+02],\n",
      "        [6.1000e+01, 0.0000e+00, 4.7792e+04, 1.2000e+02],\n",
      "        [6.8080e+03, 0.0000e+00, 4.5282e+04, 1.2000e+02],\n",
      "        [4.5900e+03, 0.0000e+00, 4.5284e+04, 1.2000e+02],\n",
      "        [1.5710e+03, 0.0000e+00, 4.4306e+04, 1.2000e+02],\n",
      "        [3.3400e+02, 0.0000e+00, 4.4056e+04, 1.2000e+02],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]), 'labels': tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0], dtype=torch.int32)}, {'boxes': tensor([[ 3122.,     0., 39582.,   120.],\n",
      "        [12472.,     0., 31461.,   120.],\n",
      "        [21228.,     0., 38628.,   120.],\n",
      "        [11969.,     0., 41813.,   120.],\n",
      "        [ 9754.,     0., 35406.,   120.],\n",
      "        [  388.,     0., 47078.,   120.],\n",
      "        [ 5436.,     0., 47433.,   120.],\n",
      "        [   72.,     0., 44590.,   120.],\n",
      "        [  413.,     0., 47960.,   120.],\n",
      "        [  338.,     0., 47860.,   120.],\n",
      "        [ 6301.,     0., 47574.,   120.],\n",
      "        [  303.,     0., 45875.,   120.],\n",
      "        [  425.,     0., 42453.,   120.],\n",
      "        [ 3563.,     0., 47065.,   120.],\n",
      "        [  691.,     0., 47985.,   120.],\n",
      "        [  853.,     0., 45020.,   120.],\n",
      "        [ 3755.,     0., 42439.,   120.],\n",
      "        [ 2813.,     0., 45852.,   120.],\n",
      "        [ 2708.,     0., 44766.,   120.],\n",
      "        [ 2631.,     0., 43469.,   120.],\n",
      "        [  896.,     0., 45186.,   120.],\n",
      "        [  344.,     0., 46809.,   120.],\n",
      "        [ 2374.,     0., 41325.,   120.],\n",
      "        [ 3738.,     0., 46740.,   120.],\n",
      "        [ 4126.,     0., 42907.,   120.],\n",
      "        [  229.,     0., 45841.,   120.],\n",
      "        [  130.,     0., 43761.,   120.],\n",
      "        [ 1149.,     0., 47752.,   120.],\n",
      "        [ 2333.,     0., 47606.,   120.],\n",
      "        [ 2053.,     0., 47162.,   120.]]), 'labels': tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0], dtype=torch.int32)}]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All bounding boxes should have positive height and width. Found invalid box [0.0, 0.0, 0.0, 0.0] for target at index 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/paulbp_dty/Desktop/P3_BBF/masked-owl-detection/oneshotdetex.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/paulbp_dty/Desktop/P3_BBF/masked-owl-detection/oneshotdetex.ipynb#ch0000011?line=0'>1</a>\u001b[0m train_loop(dataloader\u001b[39m=\u001b[39;49mdetection_dataloader, model\u001b[39m=\u001b[39;49mmodel, loss_fn\u001b[39m=\u001b[39;49mloss_fn_frrcnn, optimizer\u001b[39m=\u001b[39;49msgd_optimizer, scheduler\u001b[39m=\u001b[39;49mlr_scheduler, macro_batch\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32m/Users/paulbp_dty/Desktop/P3_BBF/masked-owl-detection/oneshotdetex.ipynb Cell 11'\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer, scheduler, macro_batch)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulbp_dty/Desktop/P3_BBF/masked-owl-detection/oneshotdetex.ipynb#ch0000010?line=12'>13</a>\u001b[0m targets \u001b[39m=\u001b[39m [{k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m t\u001b[39m.\u001b[39mitems()} \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m targets]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulbp_dty/Desktop/P3_BBF/masked-owl-detection/oneshotdetex.ipynb#ch0000010?line=13'>14</a>\u001b[0m \u001b[39m# Compute prediction error\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/paulbp_dty/Desktop/P3_BBF/masked-owl-detection/oneshotdetex.ipynb#ch0000010?line=14'>15</a>\u001b[0m losses, detections \u001b[39m=\u001b[39m model(X, targets)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulbp_dty/Desktop/P3_BBF/masked-owl-detection/oneshotdetex.ipynb#ch0000010?line=15'>16</a>\u001b[0m accumulate_losses(mean_loss, losses)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulbp_dty/Desktop/P3_BBF/masked-owl-detection/oneshotdetex.ipynb#ch0000010?line=16'>17</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(losses)\n",
      "File \u001b[0;32m~/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torchvision/models/detection/generalized_rcnn.py:90\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     88\u001b[0m             bb_idx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(degenerate_boxes\u001b[39m.\u001b[39many(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m     89\u001b[0m             degen_bb: List[\u001b[39mfloat\u001b[39m] \u001b[39m=\u001b[39m boxes[bb_idx]\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m---> 90\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     91\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mAll bounding boxes should have positive height and width.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Found invalid box \u001b[39m\u001b[39m{\u001b[39;00mdegen_bb\u001b[39m}\u001b[39;00m\u001b[39m for target at index \u001b[39m\u001b[39m{\u001b[39;00mtarget_idx\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m             )\n\u001b[1;32m     95\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackbone(images\u001b[39m.\u001b[39mtensors)\n\u001b[1;32m     96\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(features, torch\u001b[39m.\u001b[39mTensor):\n",
      "\u001b[0;31mValueError\u001b[0m: All bounding boxes should have positive height and width. Found invalid box [0.0, 0.0, 0.0, 0.0] for target at index 0."
     ]
    }
   ],
   "source": [
    "train_loop(dataloader=detection_dataloader, model=model, loss_fn=loss_fn_frrcnn, optimizer=sgd_optimizer, scheduler=lr_scheduler, macro_batch=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('audio_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2db47ff5d915a88877d09c74664ee98c88dbd61c7ef890d46532488c99d9b1a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
