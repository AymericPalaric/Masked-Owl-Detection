{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import audio_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "nn = torch.nn\n",
    "from src.utils import path_utils\n",
    "import torchinfo\n",
    "import torchvision\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifDataset(torch.utils.data.Dataset):\n",
    "\n",
    "  def __init__(self, positive_path, negative_path, hard_path, mean, std, transform_audio):\n",
    "    self.positive_path = positive_path\n",
    "    self.negative_path = negative_path\n",
    "    self.hard_path = hard_path\n",
    "    self.positive_files = [file for file in os.listdir(self.positive_path) if file.endswith(\".wav\")]\n",
    "    self.negative_files = [file for file in os.listdir(self.negative_path) if file.endswith(\".wav\")]\n",
    "    self.hard_files = [file for file in os.listdir(self.hard_path) if file.endswith(\".wav\")]\n",
    "    self.reshape_size = (129, 229)\n",
    "\n",
    "    self.transform_audio = transform_audio\n",
    "    self.transform_image = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Resize(self.reshape_size),torchvision.transforms.Normalize(mean=mean, std=std)])\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.positive_files) + len(self.negative_files) + len(self.hard_files)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    if idx < len(self.positive_files):\n",
    "      file_path = os.path.join(self.positive_path, self.positive_files[idx])\n",
    "      data, fs = audio_utils.load_audio_file(file_path)\n",
    "      x = self.transform_audio(data)\n",
    "      x = self.transform_image(x)\n",
    "      return x, 1\n",
    "    elif idx < len(self.positive_files) + len(self.negative_files):\n",
    "      file_path = os.path.join(self.negative_path, self.negative_files[idx - len(self.positive_files)])\n",
    "      data, fs = audio_utils.load_audio_file(file_path)\n",
    "      x = self.transform_audio(data)\n",
    "      x = self.transform_image(x)\n",
    "      return x, 0\n",
    "    else:\n",
    "      file_path = os.path.join(self.hard_path, self.hard_files[idx - len(self.positive_files) - len(self.negative_files)])\n",
    "      data, fs = audio_utils.load_audio_file(file_path)\n",
    "      x = self.transform_audio(data)\n",
    "      x = self.transform_image(x)\n",
    "      return x, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(train_test: bool):\n",
    "\n",
    "  def transform_audio(data):\n",
    "    _, _, specto = audio_utils.compute_spectrogram(data, 24000, nperseg=256, noverlap=256//4, scale=\"dB\")\n",
    "    # freq clip\n",
    "    specto = specto[:120, :]\n",
    "    return specto\n",
    "\n",
    "  dataset = ClassifDataset(\n",
    "    positive_path=path_utils.get_train_test_path(path_utils.get_positive_samples_path(), train_test),\n",
    "    negative_path=path_utils.get_train_test_path(path_utils.get_negative_samples_path(), train_test),\n",
    "    hard_path=path_utils.get_train_test_path(path_utils.get_hard_samples_path(), train_test),\n",
    "    mean=0.,\n",
    "    std=1.,\n",
    "    transform_audio=transform_audio)\n",
    "  \n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_dataset(train_test=True)\n",
    "test_dataset = create_dataset(train_test=False)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: -1.1142219305038452, std: 1.8928380012512207\n"
     ]
    }
   ],
   "source": [
    "mean, std = 0., 0.\n",
    "for x, y in train_dataloader:\n",
    "  mean += torch.mean(x)\n",
    "  std += torch.std(x, ) ** 2\n",
    "print(f\"mean: {mean/len(train_dataset)}, std: {(std/len(train_dataset)) ** 0.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_standadization(train_test: bool):\n",
    "\n",
    "  def transform_audio(data):\n",
    "    _, _, specto = audio_utils.compute_spectrogram(data, 24000, nperseg=256, noverlap=256//4, scale=\"dB\")\n",
    "    # freq clip\n",
    "    specto = specto[:120, :]\n",
    "    return specto\n",
    "\n",
    "  dataset = ClassifDataset(\n",
    "    positive_path=path_utils.get_train_test_path(path_utils.get_positive_samples_path(), train_test),\n",
    "    negative_path=path_utils.get_train_test_path(path_utils.get_negative_samples_path(), train_test),\n",
    "    hard_path=path_utils.get_train_test_path(path_utils.get_hard_samples_path(), train_test),\n",
    "    mean=-1.5489901304244995,\n",
    "    std=3.3042893409729004,\n",
    "    transform_audio=transform_audio)\n",
    "  \n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_dataset_standadization(train_test=True)\n",
    "test_dataset = create_dataset_standadization(train_test=False)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: -0.3224743604660034, std: 0.5711084604263306\n"
     ]
    }
   ],
   "source": [
    "mean, std = 0., 0.\n",
    "for x, y in train_dataloader:\n",
    "  mean += torch.mean(x)\n",
    "  std += torch.std(x, ) ** 2\n",
    "print(f\"mean: {mean/len(train_dataset)}, std: {(std/len(train_dataset)) ** 0.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.main = nn.Sequential(\n",
    "      nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "      nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "      nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "      nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    )\n",
    "    self.linear = nn.Linear(128, 2)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.main(x)\n",
    "    # global average pooling\n",
    "    x = nn.functional.avg_pool2d(x, kernel_size=x.shape[2:]).view(x.shape[0], -1)\n",
    "    x = self.linear(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "BasicModel                               [1, 2]                    --\n",
       "├─Sequential: 1-1                        [1, 128, 25, 12]          --\n",
       "│    └─Conv2d: 2-1                       [1, 16, 400, 200]         160\n",
       "│    └─ReLU: 2-2                         [1, 16, 400, 200]         --\n",
       "│    └─MaxPool2d: 2-3                    [1, 16, 200, 100]         --\n",
       "│    └─Conv2d: 2-4                       [1, 32, 200, 100]         4,640\n",
       "│    └─ReLU: 2-5                         [1, 32, 200, 100]         --\n",
       "│    └─MaxPool2d: 2-6                    [1, 32, 100, 50]          --\n",
       "│    └─Conv2d: 2-7                       [1, 64, 100, 50]          18,496\n",
       "│    └─ReLU: 2-8                         [1, 64, 100, 50]          --\n",
       "│    └─MaxPool2d: 2-9                    [1, 64, 50, 25]           --\n",
       "│    └─Conv2d: 2-10                      [1, 128, 50, 25]          73,856\n",
       "│    └─ReLU: 2-11                        [1, 128, 50, 25]          --\n",
       "│    └─MaxPool2d: 2-12                   [1, 128, 25, 12]          --\n",
       "├─Linear: 1-2                            [1, 2]                    258\n",
       "==========================================================================================\n",
       "Total params: 97,410\n",
       "Trainable params: 97,410\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 290.40\n",
       "==========================================================================================\n",
       "Input size (MB): 0.32\n",
       "Forward/backward pass size (MB): 19.20\n",
       "Params size (MB): 0.39\n",
       "Estimated Total Size (MB): 19.91\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BasicModel()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "torchinfo.summary(model, input_size=(1, 1, 400, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:25<03:52, 25.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:45<02:56, 22.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [01:05<02:29, 21.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:31<02:18, 23.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [01:49<01:46, 21.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [02:08<01:21, 20.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [02:28<01:00, 20.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [02:45<00:38, 19.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [03:08<00:20, 20.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n",
      "torch.Size([32, 1, 129, 229])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:25<00:00, 20.55s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(10)):\n",
    "  print(\"=\"*30)\n",
    "  for i, (x, y) in enumerate(train_dataloader):\n",
    "    loss = loss_fn(logits, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  accu = 0\n",
    "  loss = 0\n",
    "  # for i, (x, y) in enumerate(test_dataloader):\n",
    "  #   logits = model(x)\n",
    "  #   loss += loss_fn(logits, y)\n",
    "  #   accu += torch.sum(torch.argmax(logits, dim=1) == y).item()\n",
    "  # print(\"Epoch: {}, Loss: {}, Accuracy: {}\".format(epoch, loss / len(test_dataset), accu / len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "targets = []\n",
    "predictions = []\n",
    "for i, (x, y) in enumerate(test_dataloader):\n",
    "  logits = model(x)\n",
    "  predictions.extend(torch.argmax(logits, dim=1).numpy().tolist())\n",
    "  targets.extend(y.numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x129d49030>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ConfusionMatrixDisplay.from_predictions(targets, predictions, normalize=\"true\", ax=axs[0])\n",
    "ConfusionMatrixDisplay.from_predictions(targets, predictions, normalize=\"pred\", ax=axs[1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db47ff5d915a88877d09c74664ee98c88dbd61c7ef890d46532488c99d9b1a3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('audio_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
