{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import audio_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "nn = torch.nn\n",
    "from src.utils import path_utils\n",
    "import torchinfo\n",
    "import torchvision\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifDataset(torch.utils.data.Dataset):\n",
    "\n",
    "  def __init__(self, positive_path, negative_path, hard_path, mean, std, transform_audio):\n",
    "    self.positive_path = positive_path\n",
    "    self.negative_path = negative_path\n",
    "    self.hard_path = hard_path\n",
    "    self.positive_files = [file for file in os.listdir(self.positive_path) if file.endswith(\".wav\")]\n",
    "    self.negative_files = [file for file in os.listdir(self.negative_path) if file.endswith(\".wav\")]\n",
    "    self.hard_files = [file for file in os.listdir(self.hard_path) if file.endswith(\".wav\")]\n",
    "    self.reshape_size = (129, 229)\n",
    "\n",
    "    self.transform_audio = transform_audio\n",
    "    self.transform_image = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Resize(self.reshape_size),torchvision.transforms.Normalize(mean=mean, std=std)])\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.positive_files) + len(self.negative_files) + len(self.hard_files)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    if idx < len(self.positive_files):\n",
    "      file_path = os.path.join(self.positive_path, self.positive_files[idx])\n",
    "      data, fs = audio_utils.load_audio_file(file_path)\n",
    "      x = self.transform_audio(data)\n",
    "      x = self.transform_image(x)\n",
    "      return x, 1\n",
    "    elif idx < len(self.positive_files) + len(self.negative_files):\n",
    "      file_path = os.path.join(self.negative_path, self.negative_files[idx - len(self.positive_files)])\n",
    "      data, fs = audio_utils.load_audio_file(file_path)\n",
    "      x = self.transform_audio(data)\n",
    "      x = self.transform_image(x)\n",
    "      return x, 0\n",
    "    else:\n",
    "      file_path = os.path.join(self.hard_path, self.hard_files[idx - len(self.positive_files) - len(self.negative_files)])\n",
    "      data, fs = audio_utils.load_audio_file(file_path)\n",
    "      x = self.transform_audio(data)\n",
    "      x = self.transform_image(x)\n",
    "      return x, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(train_test: bool):\n",
    "\n",
    "  def transform_audio(data):\n",
    "    _, _, specto = audio_utils.compute_spectrogram(data, 24000, nperseg=256, noverlap=256//4, scale=\"dB\")\n",
    "    # freq clip\n",
    "    specto = specto[:120, :]\n",
    "    return specto\n",
    "\n",
    "  dataset = ClassifDataset(\n",
    "    positive_path=path_utils.get_train_test_path(path_utils.get_positive_samples_path(), train_test),\n",
    "    negative_path=path_utils.get_train_test_path(path_utils.get_negative_samples_path(), train_test),\n",
    "    hard_path=path_utils.get_train_test_path(path_utils.get_hard_samples_path(), train_test),\n",
    "    mean=0.,\n",
    "    std=1.,\n",
    "    transform_audio=transform_audio)\n",
    "  \n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_dataset(train_test=True)\n",
    "test_dataset = create_dataset(train_test=False)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: -1.5489901304244995, std: 3.3042893409729004\n"
     ]
    }
   ],
   "source": [
    "mean, std = 0., 0.\n",
    "for x, y in train_dataloader:\n",
    "  mean += torch.mean(x)\n",
    "  std += torch.std(x, ) ** 2\n",
    "print(f\"mean: {mean/len(train_dataset)}, std: {(std/len(train_dataset)) ** 0.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_standadization(train_test: bool):\n",
    "\n",
    "  def transform_audio(data):\n",
    "    _, _, specto = audio_utils.compute_spectrogram(data, 24000, nperseg=256, noverlap=256//4, scale=\"dB\")\n",
    "    # freq clip\n",
    "    specto = specto[:120, :]\n",
    "    return specto\n",
    "\n",
    "  dataset = ClassifDataset(\n",
    "    positive_path=path_utils.get_train_test_path(path_utils.get_positive_samples_path(), train_test),\n",
    "    negative_path=path_utils.get_train_test_path(path_utils.get_negative_samples_path(), train_test),\n",
    "    hard_path=path_utils.get_train_test_path(path_utils.get_hard_samples_path(), train_test),\n",
    "    mean=-1.5489901304244995,\n",
    "    std=3.3042893409729004,\n",
    "    transform_audio=transform_audio)\n",
    "  \n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_dataset_standadization(train_test=True)\n",
    "test_dataset = create_dataset_standadization(train_test=False)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: -0.45411789417266846, std: 0.999259352684021\n"
     ]
    }
   ],
   "source": [
    "mean, std = 0., 0.\n",
    "for x, y in train_dataloader:\n",
    "  mean += torch.mean(x)\n",
    "  std += torch.std(x, ) ** 2\n",
    "print(f\"mean: {mean/len(train_dataset)}, std: {(std/len(train_dataset)) ** 0.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.main = nn.Sequential(\n",
    "      nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "      nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "      nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "      nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    )\n",
    "    self.linear = nn.Linear(128, 2)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.main(x)\n",
    "    # global average pooling\n",
    "    x = nn.functional.avg_pool2d(x, kernel_size=x.shape[2:]).view(x.shape[0], -1)\n",
    "    x = self.linear(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "BasicModel                               --                        --\n",
       "├─Sequential: 1-1                        [1, 128, 25, 12]          --\n",
       "│    └─Conv2d: 2-1                       [1, 16, 400, 200]         160\n",
       "│    └─ReLU: 2-2                         [1, 16, 400, 200]         --\n",
       "│    └─MaxPool2d: 2-3                    [1, 16, 200, 100]         --\n",
       "│    └─Conv2d: 2-4                       [1, 32, 200, 100]         4,640\n",
       "│    └─ReLU: 2-5                         [1, 32, 200, 100]         --\n",
       "│    └─MaxPool2d: 2-6                    [1, 32, 100, 50]          --\n",
       "│    └─Conv2d: 2-7                       [1, 64, 100, 50]          18,496\n",
       "│    └─ReLU: 2-8                         [1, 64, 100, 50]          --\n",
       "│    └─MaxPool2d: 2-9                    [1, 64, 50, 25]           --\n",
       "│    └─Conv2d: 2-10                      [1, 128, 50, 25]          73,856\n",
       "│    └─ReLU: 2-11                        [1, 128, 50, 25]          --\n",
       "│    └─MaxPool2d: 2-12                   [1, 128, 25, 12]          --\n",
       "├─Linear: 1-2                            [1, 2]                    258\n",
       "==========================================================================================\n",
       "Total params: 97,410\n",
       "Trainable params: 97,410\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 290.40\n",
       "==========================================================================================\n",
       "Input size (MB): 0.32\n",
       "Forward/backward pass size (MB): 19.20\n",
       "Params size (MB): 0.39\n",
       "Estimated Total Size (MB): 19.91\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BasicModel()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "torchinfo.summary(model, input_size=(1, 1, 400, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [06:57<1:02:38, 417.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [13:34<54:01, 405.15s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [20:13<46:58, 402.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [25:38<59:50, 512.95s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/thomaslemercier/masked-owl-detection/baseline_classif.ipynb Cell 11'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomaslemercier/masked-owl-detection/baseline_classif.ipynb#ch0000007?line=4'>5</a>\u001b[0m   loss \u001b[39m=\u001b[39m loss_fn(logits, y)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomaslemercier/masked-owl-detection/baseline_classif.ipynb#ch0000007?line=5'>6</a>\u001b[0m   optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/thomaslemercier/masked-owl-detection/baseline_classif.ipynb#ch0000007?line=6'>7</a>\u001b[0m   loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomaslemercier/masked-owl-detection/baseline_classif.ipynb#ch0000007?line=7'>8</a>\u001b[0m   optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomaslemercier/masked-owl-detection/baseline_classif.ipynb#ch0000007?line=8'>9</a>\u001b[0m accu \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.9/site-packages/torch/_tensor.py?line=297'>298</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.9/site-packages/torch/_tensor.py?line=298'>299</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.9/site-packages/torch/_tensor.py?line=299'>300</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.9/site-packages/torch/_tensor.py?line=300'>301</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.9/site-packages/torch/_tensor.py?line=304'>305</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.9/site-packages/torch/_tensor.py?line=305'>306</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.9/site-packages/torch/_tensor.py?line=306'>307</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.9/site-packages/torch/autograd/__init__.py?line=150'>151</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.9/site-packages/torch/autograd/__init__.py?line=151'>152</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.9/site-packages/torch/autograd/__init__.py?line=153'>154</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.9/site-packages/torch/autograd/__init__.py?line=154'>155</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.9/site-packages/torch/autograd/__init__.py?line=155'>156</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(10)):\n",
    "  print(\"=\"*30)\n",
    "  for i, (x, y) in enumerate(train_dataloader):\n",
    "    logits = model(x)\n",
    "    loss = loss_fn(logits, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  accu = 0\n",
    "  loss = 0\n",
    "  # for i, (x, y) in enumerate(test_dataloader):\n",
    "  #   logits = model(x)\n",
    "  #   loss += loss_fn(logits, y)\n",
    "  #   accu += torch.sum(torch.argmax(logits, dim=1) == y).item()\n",
    "  # print(\"Epoch: {}, Loss: {}, Accuracy: {}\".format(epoch, loss / len(test_dataset), accu / len(test_dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "targets = []\n",
    "predictions = []\n",
    "for i, (x, y) in enumerate(test_dataloader):\n",
    "  logits = model(x)\n",
    "  predictions.extend(torch.argmax(logits, dim=1).numpy().tolist())\n",
    "  targets.extend(y.numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x131fbd6a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ConfusionMatrixDisplay.from_predictions(targets, predictions, normalize=\"true\", ax=axs[0])\n",
    "ConfusionMatrixDisplay.from_predictions(targets, predictions, normalize=\"pred\", ax=axs[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('audio_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2db47ff5d915a88877d09c74664ee98c88dbd61c7ef890d46532488c99d9b1a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
