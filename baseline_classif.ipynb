{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import audio_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "nn = torch.nn\n",
    "from src.utils import path_utils\n",
    "import torchinfo\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifDataset(torch.utils.data.Dataset):\n",
    "\n",
    "  def __init__(self, positive_path, negative_path):\n",
    "    self.positive_path = positive_path\n",
    "    self.negative_path = negative_path\n",
    "    self.positive_files = [file for file in os.listdir(self.positive_path) if file.endswith(\".wav\")]\n",
    "    self.negative_files = [file for file in os.listdir(self.negative_path) if file.endswith(\".wav\")]\n",
    "    self.reshape_size = (129, 229)\n",
    "    self.transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Resize(self.reshape_size), torchvision.transforms.Normalize((6.9260e-07,), (4.2260e-06,))])\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.positive_files) + len(self.negative_files)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    if idx < len(self.positive_files):\n",
    "      file_path = os.path.join(self.positive_path, self.positive_files[idx])\n",
    "      data, fs = audio_utils.load_audio_file(file_path)\n",
    "      _, _, Sxx = audio_utils.compute_spectrogram(data, fs, nperseg=256, noverlap=256//4)\n",
    "      Sxx = self.transform(Sxx)\n",
    "      return Sxx, 1\n",
    "    else:\n",
    "      file_path = os.path.join(self.negative_path, self.negative_files[idx - len(self.positive_files)])\n",
    "      data, fs = audio_utils.load_audio_file(file_path)\n",
    "      _, _, Sxx = audio_utils.compute_spectrogram(data, fs, nperseg=256, noverlap=256//4)\n",
    "      Sxx = self.transform(Sxx)\n",
    "      return Sxx, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ClassifDataset(path_utils.get_train_test_path(path_utils.get_positive_samples_path(), True), path_utils.get_train_test_path(path_utils.get_negative_samples_path(), True))\n",
    "test_dataset = ClassifDataset(path_utils.get_train_test_path(path_utils.get_positive_samples_path(), False), path_utils.get_train_test_path(path_utils.get_negative_samples_path(), False))\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.main = nn.Sequential(\n",
    "      nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "      nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "      nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "      nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    )\n",
    "    self.linear = nn.Linear(128, 2)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.main(x)\n",
    "    # global average pooling\n",
    "    x = nn.functional.avg_pool2d(x, kernel_size=x.shape[2:]).view(x.shape[0], -1)\n",
    "    x = self.linear(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicModel()\n",
    "torchinfo.summary(model, input_size=(1, 1, 400, 200))\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Epoch: 0, Loss: 0.011848356574773788, Accuracy: 0.8432432432432433\n",
      "==============================\n",
      "Epoch: 1, Loss: 0.010756700299680233, Accuracy: 0.8810810810810811\n",
      "==============================\n",
      "Epoch: 2, Loss: 0.009923494420945644, Accuracy: 0.8810810810810811\n",
      "==============================\n",
      "Epoch: 3, Loss: 0.007880293764173985, Accuracy: 0.8972972972972973\n",
      "==============================\n",
      "Epoch: 4, Loss: 0.006491133943200111, Accuracy: 0.9081081081081082\n",
      "==============================\n",
      "Epoch: 5, Loss: 0.00526657747104764, Accuracy: 0.9891891891891892\n",
      "==============================\n",
      "Epoch: 6, Loss: 0.0042888266034424305, Accuracy: 0.9891891891891892\n",
      "==============================\n",
      "Epoch: 7, Loss: 0.006881056819111109, Accuracy: 0.9837837837837838\n",
      "==============================\n",
      "Epoch: 8, Loss: 0.0018914921674877405, Accuracy: 0.9891891891891892\n",
      "==============================\n",
      "Epoch: 9, Loss: 0.004660426173359156, Accuracy: 0.9891891891891892\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "  print(\"=\"*30)\n",
    "  for i, (x, y) in enumerate(train_dataloader):\n",
    "    logits = model(x)\n",
    "    loss = loss_fn(logits, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  accu = 0\n",
    "  loss = 0\n",
    "  for i, (x, y) in enumerate(test_dataloader):\n",
    "    logits = model(x)\n",
    "    loss += loss_fn(logits, y)\n",
    "    accu += torch.sum(torch.argmax(logits, dim=1) == y).item()\n",
    "  print(\"Epoch: {}, Loss: {}, Accuracy: {}\".format(epoch, loss / len(test_dataset), accu / len(test_dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x125a2bf40>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATIAAAEGCAYAAADmLRl+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWXUlEQVR4nO3de5gddX3H8fdnNxuSQC7mQgwbkIiYGFCBxiBSeYLSEtQWb7UCVdpCKSraSn0qXioWxdZqaymiEoGKrYJcBeUSFKQIrSEJIJAAErmEkMTcQQi57Nlv/zizsInJnpnkXOZ39vN6nnlyZs7Zme/uPvvJ7/ebmd8oIjAzS1lHqwswM9tdDjIzS56DzMyS5yAzs+Q5yMwseUNaXUB/Y8d2RPfkzlaXYQU8+cDIVpdgBWziebbEZu3OPo49es9Yu66S67ML7988NyJm787x8ihVkHVP7uSHN4xvdRlWwOmv+P1Wl2AFzItbd3sfa9ZVmDd3cq7Pdk36dVP+oEsVZGaWgqASva0uYhsOMjMrJIBeynUhvYPMzArrxS0yM0tYEGx119LMUhZAxV1LM0udx8jMLGkBVEo2a46DzMwKK9cImYPMzAoKwmNkZpa2CNharhxzkJlZUaLCbt2uWXcOMjMrJIBet8jMLHVukZlZ0qoXxDrIzCxhAWyNcs3J6iAzs0ICUSnZ5NIOMjMrrDfctTSzhHmMzMzagKh4jMzMUladIdZBZmYJixBbolxPO3OQmVlhvR4jM7OUVQf73bU0s6R5sN/MEufBfjNrCxVfEGtmKQvE1ihXdJSrGjMrvTIO9perGjMrvUBUIt9Si6SPS1ok6UFJl0kaJmmKpHmSlkj6gaShtfbjIDOzwnrpyLUMRFI38DFgRkQcDHQC7we+DHwtIl4FrAdOqVWPg8zMComASnTkWnIYAgyXNAQYAawA3gJclb1/KfDOPDsxM8utOtif+xal8ZIW9FufExFzACLiaUlfBZYCLwC3AAuBDRHRk31+GdBd6yAOMjMrrMBg/5qImLGjNyS9DDgemAJsAK4EZu9KPQ4yMyskUL0mVjwGeDwiVgNIugY4EhgjaUjWKpsMPF1rRx4jM7PCKnTkWmpYCrxR0ghJAt4KLAZ+Brw3+8zJwHW1duQgM7NCqs+17Mi1DLifiHlUB/XvAR6gmkdzgE8CZ0paAowDLq5Vk7uWZlZQ/Z40HhFnA2dvt/kxYGaR/TjIzKyQ6uPgPLGimSUsQjW7jc3mIDOzwjwfmZklrTofmafxMbOkeYZYM0tc9fILt8jMLGEF77VsCgeZmRXmOfvNLGnVaXzctTSzxHmMzMySVp39wl1LM0tY9RYlB1lb++lF+3DX5RORYJ9pGzn5K7/i1wtHcfW5U6hsFfu99jk+8C+P0umffCnNmPUsp39hOZ0dwU2XjeWKr09sdUklVL4WWUOrkTRb0iPZ01DOauSxymD9yqH87D/34VM//iWf+8m99Fbg7uv25tK/ezWnfv1hPveTexnbvZlfXOU/jjLq6Ag+8qWn+exJU/irWVM5+vgN7HfgplaXVUq9KNfSLA0LMkmdwAXAccB04ARJ0xt1vLLorYitmzqo9MDWFzrZY0SFzq5eJr6y+gfxmjdv4J6bxrW4StuRqYduZPkTQ1m5dA96tnZw+3VjOOLYZ1pdVun0nbWsx+Pg6qWRLbKZwJKIeCwitgCXU52fu2297OVbOOa0p/n0EW/gk284nGEje/i9d6yhtyKevH8vAO65cTzrV+zR4kptR8a9fCurl7/0CMU1K7oYP2lrCysqr3pMrFhPjRyp6Qae6re+DDh8+w9JOg04DWCf7nL1u4t6/plO7r9lLF+8cz4jRlWY8+Fp3H3tBE49/xGuPGcKW7d0MP3N6+nojFaXarbL6jhnf920fMg5ezTUHIDXvq4r6b/wh+8cw7h9NzFyXPVJVofOXsuvF47i8Hev5hNXPQDA4jvG8JvHh7eyTNuJtSu7mLDPlhfXx0/aypoVXS2sqJwC6BlEg/1PA/v2W8/1NJSUjd1nM4/fO5ItL3QQAQ/fNZpJr9rIs2uqfwxbN4u535zMUSetbHGltiOP3DeC7ilbmLjvZoZ09TLr+A384pbRrS6rlAZT13I+cKCkKVQD7P3AiQ08XstNOfQ5DnvbWs59+yF0dgb7HvQ8v3/iSq7/6it44NaxRMBRf7aSaUd6ALmMeivigs9086XvP0ZHJ9xy+Vie/NWwVpdVPjGIupYR0SPpDGAu0AlcEhGLGnW8svijM5fyR2cu3Wbbez7zBO/5zBOtKcgKmX/bKObfNqrVZZTaoJtYMSJuBG5s5DHMrPkGTYvMzNqTJ1Y0s+QFoqe3XGctHWRmVtigGiMzszYU7lqaWeI8RmZmbcFBZmZJC0TFg/1mljoP9ptZ0sKD/WbWDsJBZmZpG0Q3jZtZ+3KLzMySFgGVXgeZmSXOZy3NLGlB+bqW5bqqzcwSUB3sz7PU3JM0RtJVkh6W9JCkIySNlfQTSY9m/76s1n4cZGZWWES+JYfzgJsjYhrweuAh4Czg1og4ELg1Wx+Qg8zMCotQrmUgkkYDRwEXV/cZWyJiA9Xn316afexS4J216vEYmZkVUj1rmbsNNF7Sgn7rc7JHQAJMAVYD/ynp9cBC4G+AiRGxIvvMSmBirYM4yMyssJzdRoA1ETFjJ+8NAQ4DPhoR8ySdx3bdyIgISTWP5q6lmRVWj64lsAxYFhHzsvWrqAbbbyRNAsj+XVVrRw4yMyskyBditYIsIlYCT0mamm16K7AYuB44Odt2MnBdrZrctTSzwvL3LGv6KPA9SUOBx4C/oNrAukLSKcCTwPtq7cRBZmbFBESdblGKiPuAHY2hvbXIfhxkZlZY2a7sd5CZWWEFzlo2xU6DTNL5DNAVjoiPNaQiMyu1Mt5rOVCLbMEA75nZYBVAKkEWEZf2X5c0IiI2Nr4kMyu7snUta15Hlt2Nvhh4OFt/vaRvNLwyMyspEb35lmbJc0HsvwPHAmsBIuKXVG/0NLPBKnIuTZLrrGVEPCVtk66VxpRjZqUXaQ3293lK0puAkNRF9e70hxpblpmVWmpjZMDpwEeAbmA5cEi2bmaDlnIuzVGzRRYRa4CTmlCLmaWit9UFbCvPWctXSvqRpNWSVkm6TtIrm1GcmZVQ33VkeZYmydO1/D5wBTAJ2Ae4EriskUWZWbnVcc7+usgTZCMi4r8ioidb/hsY1ujCzKzEUrn8QtLY7OVNks4CLqda2p8CNzahNjMrq4Quv1hINbj6Kv7rfu8F8KlGFWVm5VZ7Fv3mGuheyynNLMTMEhGCJt5+lEeuK/slHQxMp9/YWER8t1FFmVnJpdIi6yPpbGAW1SC7ETgOuBNwkJkNViULsjxnLd9Ldf7slRHxF1Qfaz66oVWZWbmlctaynxcioldSj6RRVJ8xt2+D6zKzskppYsV+FkgaA3yb6pnM54D/a2RRZlZuyZy17BMRH85efkvSzcCoiLi/sWWZWamlEmSSDhvovYi4pzElmVnZpdQi+9cB3gvgLXWuhScfHMWHXl3ouZzWYnOXz2t1CVbAzGPr9NiNVMbIIuLoZhZiZolo8hnJPPyAXjMrzkFmZqlTySZWdJCZWXEla5HlmSFWkv5M0uey9f0kzWx8aWZWRor8S7PkuUXpG8ARwAnZ+m+BCxpWkZmVX8mmus7TtTw8Ig6TdC9ARKyXNLTBdZlZmZWsa5knyLZK6iQrXdIESvcMFTNrppQuiO3zH8C1wN6SzqU6G8ZnG1qVmZVXJHjWMiK+J2kh1al8BLwzIvykcbPBLLUWmaT9gI3Aj/pvi4iljSzMzEostSADbuClh5AMA6YAjwAHNbAuMyuxso2R1bz8IiJeGxGvy/49EJiJ5yMzszqR1CnpXkk/ztanSJonaYmkH+S5SiLPdWTbyKbvOXwX6jWzdlHfqa7/Bug/7v5l4GsR8SpgPXBKrR3kGSM7s99qB3AYsDx3iWbWXup41lLSZODtwLnAmZJEdYqwE7OPXAp8HvjmQPvJM0Y2st/rHqpjZlcXrNfM2kn+1tZ4SQv6rc+JiDn91v8d+HteyplxwIaI6MnWlwHdtQ4yYJBlF8KOjIhP5K3azNqbKDTYvyYiZuxwP9I7gFURsVDSrN2paaCprodERI+kI3fnAGbWhupz1vJI4I8lvY3qFRGjgPOAMX35A0wGnq61o4EG++/O/r1P0vWSPiDp3X3Lbn4DZpaqOs1+ERGfiojJEbE/8H7gtog4CfgZ1TuIAE4GrqtVUp4xsmHAWqoDcH3XkwVwTY6vNbN21NhblD4JXC7pi8C9wMW1vmCgINs7O2P5IC8FWJ+SXQ5nZs1U7wtiI+J24Pbs9WNUr1fNbaAg6wT2YtsAe/G4RQ5iZm2mZAkwUJCtiIhzmlaJmaUhsacolevBdWZWGmW713KgIPOTcs1sx1IJsohY18xCzCwdyU2saGa2jcTGyMzMfoco3wC6g8zMinOLzMxSl9JZSzOzHXOQmVnSUnwcnJnZ73CLzMxS5zEyM0ufg8zMUucWmZmlLWj0xIqFOcjMrJCCDx9pCgeZmRXnIDOz1CnKlWQOMjMrxrNfmFk78BiZmSXPtyiZWfrcIjOzpOV4inizOcjMrDgHmZmlzBfEmllbUG+5ksxBZmbFlPA6so5WF9Cuxk/azJe//xAX3nI/F859gOP/fGWrS7KduPai8Zx29FT+atZUrvn2hG3eu+pbEzh2n0N4Zm1ni6orJ/XmW5qlYS0ySZcA7wBWRcTBjTpOWfX2iG+fux9LFu3J8D0rnP+jB7n3ztEsXTK81aVZP088PIybvjeO/7jhV3QNDT594gEcfswzdE/Zwqqnu7jnf0ayd/eWVpdZPoOoRfYdYHYD919q61YPZcmiPQF44flOnloynHEv9x9E2Sx9dA+mHbqRYSOCziHwuiOe464bxwBw4ee7OeWzy1HZHuJYAop8S7M0LMgi4g5gXaP2n5KJ3Zs5YPpGHrlvr1aXYtvZf9omHrx7T55d18mmjWL+baNYvbyL/715FONfvpUDDtrU6hLLJ4CIfEuTtHywX9JpwGkAwxjR4mrqb9iICp/95qNc+IX92Picx1nKZr8DN/O+D6/iUyccwLARvbzyoBfYukVcfv5E/umyX7e6vNIq2y1KLR/sj4g5ETEjImZ0aViry6mrziG9/MM3H+Vn143jrrljW12O7cTsE9dxwdxf8a/XLmGv0RVeMXUTK5cO5UPHTOODM6ezekUXHzl2KutWtfz//VLou46sTF1L/2YaJvj4lx9n6ZLhXHPxpFYXYwPYsGYIY8b3sGpZF3fdOJrzfvwo7zp1zYvvf3DmdM6/6RFGj6u0sMoSaXK3MQ8HWYMcNOM5jnn3Wh5/eDgX3PAgAN/5ymTm3z6mtYXZ7zjn1P357fohdHYFZ3xpGXuNdmDVMmiu7Jd0GTALGC9pGXB2RFzcqOOVzaIFI5k9ZWary7Ac/u2HSwZ8/7t3L25SJQkZLEEWESc0at9m1lr1aJFJ2hf4LjCRajTOiYjzJI0FfgDsDzwBvC8i1g+0r5YP9ptZYgKoRL5lYD3A30XEdOCNwEckTQfOAm6NiAOBW7P1ATnIzKywepy1jIgVEXFP9vq3wENAN3A8cGn2sUuBd9aqx4P9ZlZcnc9aStofOBSYB0yMiBXZWyupdj0H5CAzs8IKjJGNl7Sg3/qciJizzb6kvYCrgb+NiGfV756wiAip9tEcZGZWTLFpfNZExIydvSmpi2qIfS8irsk2/0bSpIhYIWkSsKrWQTxGZmaFCFAlci0D7qfa9LoYeCgi/q3fW9cDJ2evTwauq1WTW2RmVlidnjR+JPAB4AFJ92XbPg38M3CFpFOAJ4H31dqRg8zMiqnTDLERcSfVBt6OvLXIvhxkZlaQ77U0szYwaO61NLM25haZmSUtqHlGstkcZGZWXLlyzEFmZsXV6fKLunGQmVlxDjIzS1oAJXv4iIPMzAoR4a6lmbWB3nI1yRxkZlaMu5Zm1g7ctTSz9DnIzCxtvmnczFLX9xSlEnGQmVlhHiMzs/Q5yMwsaQH0OsjMLGke7DezduAgM7OkBVAp16X9DjIzKyggHGRmljp3Lc0saT5raWZtwS0yM0ueg8zMkhYBlUqrq9iGg8zMinOLzMyS5yAzs7SFz1qaWeICwhfEmlnyfIuSmSUtwo+DM7M24MF+M0tduEVmZmnzxIpmljrfNG5mqQsgSnaLUkerCzCzxEQ2sWKepQZJsyU9ImmJpLN2tSS3yMyssKhD11JSJ3AB8AfAMmC+pOsjYnHRfblFZmbF1adFNhNYEhGPRcQW4HLg+F0pR1Gisw+SVgNPtrqOBhgPrGl1EVZIu/7OXhERE3ZnB5JupvrzyWMYsKnf+pyImJPt573A7Ig4NVv/AHB4RJxRtKZSdS139wdcVpIWRMSMVtdh+fl3tnMRMbvVNWzPXUsza5WngX37rU/OthXmIDOzVpkPHChpiqShwPuB63dlR6XqWraxOa0uwArz76zBIqJH0hnAXKATuCQiFu3Kvko12G9mtivctTSz5DnIzCx5DrIGqtftF9Y8ki6RtErSg62uxfJzkDVIv9svjgOmAydImt7aqiyH7wClu07KBuYga5y63X5hzRMRdwDrWl2HFeMga5xu4Kl+68uybWZWZw4yM0ueg6xx6nb7hZkNzEHWOHW7/cLMBuYga5CI6AH6br94CLhiV2+/sOaRdBnwf8BUScskndLqmqw236JkZslzi8zMkucgM7PkOcjMLHkOMjNLnoPMzJLnIEuIpIqk+yQ9KOlKSSN2Y1/fyZ5ig6SLBrqhXdIsSW/ahWM8Iel3nrazs+3bfea5gsf6vKRPFK3R2oODLC0vRMQhEXEwsAU4vf+bknZp6vKIOLXGQ1FnAYWDzKxZHGTp+jnwqqy19HNJ1wOLJXVK+oqk+ZLul/TXAKr6ejY/2k+Bvft2JOl2STOy17Ml3SPpl5JulbQ/1cD8eNYafLOkCZKuzo4xX9KR2deOk3SLpEWSLgJU65uQ9ENJC7OvOW27976Wbb9V0oRs2wGSbs6+5ueSptXlp2lJ88NHEpS1vI4Dbs42HQYcHBGPZ2HwTES8QdIewF2SbgEOBaZSnRttIrAYuGS7/U4Avg0cle1rbESsk/Qt4LmI+Gr2ue8DX4uIOyXtR/XuhdcAZwN3RsQ5kt4O5Lkq/i+zYwwH5ku6OiLWAnsCCyLi45I+l+37DKoPBTk9Ih6VdDjwDeAtu/BjtDbiIEvLcEn3Za9/DlxMtct3d0Q8nm3/Q+B1feNfwGjgQOAo4LKIqADLJd22g/2/Ebijb18RsbN5uY4BpksvNrhGSdorO8a7s6+9QdL6HN/TxyS9K3u9b1brWqAX+EG2/b+Ba7JjvAm4st+x98hxDGtzDrK0vBARh/TfkP1BP99/E/DRiJi73efeVsc6OoA3RsSmHdSSm6RZVEPxiIjYKOl2YNhOPh7ZcTds/zMw8xhZ+5kLfEhSF4CkV0vaE7gD+NNsDG0ScPQOvvYXwFGSpmRfOzbb/ltgZL/P3QJ8tG9F0iHZyzuAE7NtxwEvq1HraGB9FmLTqLYI+3QAfa3KE6l2WZ8FHpf0J9kxJOn1NY5hg4CDrP1cRHX8657sARoXUm15Xws8mr33XaozPGwjIlYDp1Htxv2Sl7p2PwLe1TfYD3wMmJGdTFjMS2dP/5FqEC6i2sVcWqPWm4Ehkh4C/plqkPZ5HpiZfQ9vAc7Jtp8EnJLVtwhPH2549gszawNukZlZ8hxkZpY8B5mZJc9BZmbJc5CZWfIcZGaWPAeZmSXv/wGLsaQ80vk9WwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "targets = []\n",
    "predictions = []\n",
    "for i, (x, y) in enumerate(test_dataloader):\n",
    "  logits = model(x)\n",
    "  predictions.extend(torch.argmax(logits, dim=1).numpy().tolist())\n",
    "  targets.extend(y.numpy().tolist())\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(targets, predictions)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
