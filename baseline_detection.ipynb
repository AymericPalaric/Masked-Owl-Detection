{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.utils.audio_utils import compute_spectrogram, load_audio_file, padding_audio\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "nn = torch.nn\n",
    "from src.utils import path_utils\n",
    "import torchinfo\n",
    "import torchvision\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.main = nn.Sequential(\n",
    "      nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "      nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "      nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "      nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    )\n",
    "    self.linear = nn.Linear(128, 2)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.main(x)\n",
    "    # global average pooling\n",
    "    x = nn.functional.avg_pool2d(x, kernel_size=x.shape[2:]).view(x.shape[0], -1)\n",
    "    x = self.linear(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, raw_dir, transform_audio, window_size, stride):\n",
    "\n",
    "        self.tensor_directory = raw_dir\n",
    "        self.transform_audio = transform_audio\n",
    "        self.reshape_size = (129, 229)\n",
    "        self.transform_image = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Resize(self.reshape_size)])\n",
    "        self.files = os.listdir(raw_dir)\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.data_tuples = []\n",
    "\n",
    "        for f in self.files:\n",
    "            file = os.path.join(raw_dir, f)\n",
    "            data, fs = load_audio_file(file)\n",
    "            # pad with zeros with tensor is not of right length\n",
    "            data = padding_audio(data, self.window_size)\n",
    "            idxs = [i for i in range(0, data.size - self.window_size, self.stride)]\n",
    "            if len(idxs) == 0:\n",
    "                continue\n",
    "            for j in idxs:\n",
    "                data_tuple = (file, j)\n",
    "                self.data_tuples.append(data_tuple)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_tuples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_tuple = self.data_tuples[idx]\n",
    "        sample, _ = load_audio_file(sample_tuple[0])\n",
    "        sample = sample[sample_tuple[1]: sample_tuple[1] + self.window_size]\n",
    "        x = self.transform_audio(sample)\n",
    "        print(x.shape)\n",
    "        x = self.transform_image(x)\n",
    "        print(x.shape)\n",
    "        return {'sample': sample, 'file': sample_tuple[0], 'index': sample_tuple[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulbp_dty/Desktop/P3_BBF/masked-owl-detection/src/utils/audio_utils.py:12: FutureWarning: Pass size=86352128 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  data=librosa.util.fix_length(data, data.size + window_size - data.size % window_size)\n"
     ]
    }
   ],
   "source": [
    "def transform_audio(data):\n",
    "    _, _, specto = compute_spectrogram(data, 24000, nperseg=256, noverlap=256/2, scale=\"dB\")\n",
    "    # freq clip\n",
    "    specto = specto[:120, :]\n",
    "    return specto\n",
    "detection_dataloader = torch.utils.data.DataLoader(SlidingDataset(raw_dir=path_utils.get_raw_data_path(),\n",
    "                                                    transform_audio=transform_audio, \n",
    "                                                    window_size=256, stride=128),\n",
    "                                                    batch_size=1, \n",
    "                                                    drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 1)\n",
      "torch.Size([1, 129, 229])\n",
      "torch.Size([1, 256])\n",
      "['./data/raw_data/SMA01214_20210809_233002.wav']\n",
      "tensor([0])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [1, 256]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/paulbp_dty/Desktop/P3_BBF/masked-owl-detection/baseline_detection.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/paulbp_dty/Desktop/P3_BBF/masked-owl-detection/baseline_detection.ipynb#ch0000003?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(x[\u001b[39m'\u001b[39m\u001b[39mfile\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/paulbp_dty/Desktop/P3_BBF/masked-owl-detection/baseline_detection.ipynb#ch0000003?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(x[\u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/paulbp_dty/Desktop/P3_BBF/masked-owl-detection/baseline_detection.ipynb#ch0000003?line=6'>7</a>\u001b[0m logits\u001b[39m=\u001b[39mmodel(x[\u001b[39m'\u001b[39;49m\u001b[39msample\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/paulbp_dty/Desktop/P3_BBF/masked-owl-detection/baseline_detection.ipynb#ch0000003?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39margmax(logits, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mtolist())\n",
      "File \u001b[0;32m~/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/paulbp_dty/Desktop/P3_BBF/masked-owl-detection/baseline_detection.ipynb Cell 2'\u001b[0m in \u001b[0;36mBasicModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulbp_dty/Desktop/P3_BBF/masked-owl-detection/baseline_detection.ipynb#ch0000001?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/paulbp_dty/Desktop/P3_BBF/masked-owl-detection/baseline_detection.ipynb#ch0000001?line=20'>21</a>\u001b[0m   x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmain(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulbp_dty/Desktop/P3_BBF/masked-owl-detection/baseline_detection.ipynb#ch0000001?line=21'>22</a>\u001b[0m   \u001b[39m# global average pooling\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulbp_dty/Desktop/P3_BBF/masked-owl-detection/baseline_detection.ipynb#ch0000001?line=22'>23</a>\u001b[0m   x \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mavg_pool2d(x, kernel_size\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m:])\u001b[39m.\u001b[39mview(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:447\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=445'>446</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=446'>447</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:443\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=438'>439</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=439'>440</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=440'>441</a>\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=441'>442</a>\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=442'>443</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    <a href='file:///Users/paulbp_dty/Desktop/P3_BBF/audio_env/lib/python3.10/site-packages/torch/nn/modules/conv.py?line=443'>444</a>\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [1, 256]"
     ]
    }
   ],
   "source": [
    "model = BasicModel()\n",
    "\n",
    "for x in detection_dataloader:\n",
    "  print(x['sample'].shape)\n",
    "  print(x['file'])\n",
    "  print(x['index'])\n",
    "  logits=model(x['sample'])\n",
    "  print(torch.argmax(logits, dim=1).numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db47ff5d915a88877d09c74664ee98c88dbd61c7ef890d46532488c99d9b1a3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('audio_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
